{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import scipy.stats as stats\n",
    "import itertools as it\n",
    "import math \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pyswarms as ps\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsen_adsize = 1.7 #parameter related to sensivity of fecundity to adult size\\nsen_adden = 0.17 #parameter related to sensivity of fecundity to adult denisity\\nf = 0#migration rate\\n\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##define the fixed parameters\n",
    "hatchability = 0.98  #if hatchability is density (egg or adult) depedent, then define it in the pre-adult-module or the adult-module functions \n",
    "x1 = 2.5  #parameter in finding the mean larval size\n",
    "x2 = 1  #parameter in finding the mean larval size \n",
    "x3 = 0.009 #parameter in finding the mean larval size \n",
    "sigma_size = 0.45  #parameter in assigning larval sizes by drawing from a normal distribution\n",
    "mc = 1.1 #critical size cut off of the larval stage for successful pupation (= 1.1 (JB) and 1 (FEJ))\n",
    "x4 = 1.0  #parameter in finding the adult sizes\n",
    "female_proportion = 0.5 #assign sex to the adutls \n",
    "x5 = 85 #parameter in finding fecundity\n",
    "x6 = 2  #parameter in finding fecundity\n",
    "\n",
    "'''\n",
    "sen_adsize = 1.7 #parameter related to sensivity of fecundity to adult size\n",
    "sen_adden = 0.17 #parameter related to sensivity of fecundity to adult denisity\n",
    "f = 0#migration rate\n",
    "\n",
    "'''\n",
    "#pre-defning all parameters requriref for adult module and pre-adult module, as well as migration. These parameters are re-defined according to the simulatuion wer taking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Pre-Adult-Module\n",
    "#food = larval food amt; 1.76 (LL and LH), 2.56 (HL and HH) \n",
    "\n",
    "\n",
    "def Pre_Adult_Module(numegg,food):\n",
    "    \"\"\"  \n",
    "This function takes the number of eggs in gen t and larval food amount as input and returns the number of adults in gen t and their size distribution as output.\n",
    "\n",
    "Args: \n",
    "    numegg (int): number of eggs in generation t\n",
    "    food (float): larval food amount in ml\n",
    "\n",
    "Returns:\n",
    "    numadult (int): number of adults in generation t\n",
    "    size_adult_arr (array): size distribution of adults in generation t\n",
    "\"\"\"\n",
    "    numlarva = int(hatchability*numegg)\n",
    "    mean_size = x1*(1-1/(x2+np.exp(-x3*numlarva+food)))\n",
    "    size_larva_arr = abs(np.random.normal(mean_size, sigma_size, numlarva))\n",
    "    numadult = (size_larva_arr>=mc).sum()\n",
    "    size_adult_arr = x4*size_larva_arr[size_larva_arr>=mc]\n",
    "    return numadult, size_adult_arr\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Demographic-Stochasticity\n",
    "\n",
    "def Demo_Stoch(numadult, size_adult_arr):\n",
    "    \"\"\"  \n",
    "This function takes the number of adults in gen t and their size distribution, if their number is less than 8 then it is reduced to 0 by 50 % chance\n",
    "\n",
    "Args: \n",
    "    numadult (int): number of adults in generation t before demographic stochasticity\n",
    "    size_adult_arr (array): size distribution of adults in generation t before demographic stochasticity\n",
    "\n",
    "Returns:\n",
    "    numadult (int): number of adults in generation t after demographic stochasticity\n",
    "    size_adult_arr (array): size distribution of adults in generation t after demographic stochasticity\n",
    "    \"\"\"\n",
    "    if numadult < 8:\n",
    "        numadult = np.random.binomial(size=1, n=1, p=0.5)*numadult # numadult either remains the same or is reduced to 0\n",
    "        numadult = numadult[0] \n",
    "        if numadult == 0:\n",
    "            size_adult_arr = np.array([])\n",
    "    return numadult, size_adult_arr\n",
    "\n",
    "\n",
    "\n",
    "#demographic stoch. is not implemneted in metapop case, because stochasiticity is quite low\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Female_Size\n",
    "\n",
    "def Female_Size(size_adult_arr):\n",
    "    \"\"\"  \n",
    "This function takes size_adult_arr as input and returns female_size_arr as output.\n",
    "\n",
    "Args: \n",
    "    size_adult_arr (array): size distribution of adults in generation t\n",
    "\n",
    "Returns:\n",
    "    size_female_arr (array): size distribution of only females in generation t\n",
    "\"\"\"\n",
    "    numadult = np.shape(size_adult_arr)[0]\n",
    "    adult_sex_arr = np.random.binomial(size=numadult, n=1, p=female_proportion) # 1 is a female and 0 a male\n",
    "    size_female_arr = size_adult_arr[adult_sex_arr == 1]\n",
    "    return size_female_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Metapopulation_Reset\n",
    "\n",
    "def Metapopulation_Reset(numadult1,numadult2,size_female_arr1,size_female_arr2):\n",
    "    \"\"\"\n",
    "This function takes numadult and size_female_arr of both patches post-demo-stoch as inputs and returns numadult and size_female_arr of both patches after metapopulation reset as output.\n",
    "\n",
    "Args: \n",
    "    numadult1 (int): number of adults in patch 1 in generation t post-demo-stoch pre-metapopulation-reset\n",
    "    numadult2 (int): number of adults in patch 2 in generation t post-demo-stoch pre-metapopulation-reset   \n",
    "    size_female_arr1 (array): size distribution of females in patch 1 in generation t post-demo-stoch pre-metapopulation-reset\n",
    "    size_female_arr2 (array): size distribution of females in patch 2 in generation t post-demo-stoch pre-metapopulation-reset\n",
    "\n",
    "Returns:\n",
    "    numadult1 (int): number of adults in patch 1 in generation t post-metapopulation-reset\n",
    "    numadult2 (int): number of adults in patch 2 in generation t post-metapopulation-reset  \n",
    "    size_female_arr1 (array): size distribution of females in patch 1 in generation t post-metapopulation-reset\n",
    "    size_female_arr2 (array): size distribution of females in patch 2 in generation t post-metapopulation-reset\n",
    "\"\"\"\n",
    "    if numadult1 == 0 and numadult2 == 0:\n",
    "        numadult1 = 8 #resetting the population to 4 males and 4 females\n",
    "        numadult2 = 8\n",
    "        size_female_arr1 = 2*mc*np.ones(int(numadult1/2))\n",
    "        size_female_arr2 = 2*mc*np.ones(int(numadult2/2))\n",
    "\n",
    "    return numadult1,numadult2,size_female_arr1,size_female_arr2\n",
    "\n",
    "\n",
    "#there is metapopulation reset\n",
    "#num_adult_1 and num_adult_2 are patch 1 and patch 2 number of adults respectvely. Reset happens only when both go to zero. then both are reset with 8 and 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Migration\n",
    "\n",
    "def Migration_with_f(numadult1,numadult2,size_female_arr1,size_female_arr2, f_val):\n",
    "    \"\"\"  \n",
    "This function takes numadult and size_female_arr of both patches as inputs and returns numadult and size_female_arr of both patches post migration as output.\n",
    "\n",
    "Args: \n",
    "    numadult1 (int): number of adults in patch 1 in generation t pre-migration\n",
    "    numadult2 (int): number of adults in patch 2 in generation t pre-migration    \n",
    "    size_female_arr1 (array): size distribution of females in patch 1 in generation t pre-migration\n",
    "    size_female_arr2 (array): size distribution of females in patch 2 in generation t pre-migration\n",
    "\n",
    "Returns:\n",
    "    numadult1 (int): number of adults in patch 1 in generation t post-migration\n",
    "    numadult2 (int): number of adults in patch 2 in generation t post-migration    \n",
    "    size_female_arr1 (array): size distribution of females in patch 1 in generation t post-migration\n",
    "    size_female_arr2 (array): size distribution of females in patch 2 in generation t post-migration\n",
    "\"\"\"\n",
    "    mig_female_12 = size_female_arr1[(len(size_female_arr1)-round(f_val*numadult1/2)):]\n",
    "    #print(mig_female_12)\n",
    "    mig_female_21 = size_female_arr2[(len(size_female_arr2)-round(f_val*numadult2/2)):]\n",
    "    #print(mig_female_21)\n",
    "    size_female_arr1 = np.concatenate((size_female_arr1[0:(len(size_female_arr1)-round(f*numadult1/2))],mig_female_21))\n",
    "    #print(size_female_arr1)\n",
    "    size_female_arr2 = np.concatenate((size_female_arr2[0:(len(size_female_arr2)-round(f*numadult2/2))],mig_female_12))\n",
    "    #print(size_female_arr2)\n",
    "    numadult1_update = numadult1 - round(f_val*numadult1/2) + round(f_val*numadult2/2)\n",
    "    numadult2_update = numadult2 - round(f_val*numadult2/2) + round(f_val*numadult1/2)\n",
    "    numadult1 = numadult1_update\n",
    "    numadult2 = numadult2_update\n",
    "    return numadult1,numadult2,size_female_arr1,size_female_arr2\n",
    "\n",
    "#num adult 1, size_female_arr 1 -> females in patch 1 and their sizes. Size female arr 2 -> females in patch 2 arr 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Migration fucntio that explicity takes f as input\n",
    "\n",
    "##Migration\n",
    "\n",
    "def Migration(numadult1,numadult2,size_female_arr1,size_female_arr2):\n",
    "    \"\"\"  \n",
    "This function takes numadult and size_female_arr of both patches as inputs and returns numadult and size_female_arr of both patches post migration as output.\n",
    "\n",
    "Args: \n",
    "    numadult1 (int): number of adults in patch 1 in generation t pre-migration\n",
    "    numadult2 (int): number of adults in patch 2 in generation t pre-migration    \n",
    "    size_female_arr1 (array): size distribution of females in patch 1 in generation t pre-migration\n",
    "    size_female_arr2 (array): size distribution of females in patch 2 in generation t pre-migration\n",
    "\n",
    "Returns:\n",
    "    numadult1 (int): number of adults in patch 1 in generation t post-migration\n",
    "    numadult2 (int): number of adults in patch 2 in generation t post-migration    \n",
    "    size_female_arr1 (array): size distribution of females in patch 1 in generation t post-migration\n",
    "    size_female_arr2 (array): size distribution of females in patch 2 in generation t post-migration\n",
    "\"\"\"\n",
    "    mig_female_12 = size_female_arr1[(len(size_female_arr1)-round(f*numadult1/2)):]\n",
    "    #print(mig_female_12)\n",
    "    mig_female_21 = size_female_arr2[(len(size_female_arr2)-round(f*numadult2/2)):]\n",
    "    #print(mig_female_21)\n",
    "    size_female_arr1 = np.concatenate((size_female_arr1[0:(len(size_female_arr1)-round(f*numadult1/2))],mig_female_21))\n",
    "    #print(size_female_arr1)\n",
    "    size_female_arr2 = np.concatenate((size_female_arr2[0:(len(size_female_arr2)-round(f*numadult2/2))],mig_female_12))\n",
    "    #print(size_female_arr2)\n",
    "    numadult1_update = numadult1 - round(f*numadult1/2) + round(f*numadult2/2)\n",
    "    numadult2_update = numadult2 - round(f*numadult2/2) + round(f*numadult1/2)\n",
    "    numadult1 = numadult1_update\n",
    "    numadult2 = numadult2_update\n",
    "    return numadult1,numadult2,size_female_arr1,size_female_arr2\n",
    "\n",
    "#num adult 1, size_female_arr 1 -> females in patch 1 and their sizes. Size female arr 2 -> females in patch 2 arr 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adult-Module\n",
    "#adnut = #adult food nutrition quality; 1 (LL and HL), 1.29 (HH) and 1.49 (LH)\n",
    "\n",
    "def Adult_Module(numadult, size_female_arr,adnut):\n",
    "    \"\"\"  \n",
    "This function takes the number of adults in gen t, the female size distribution and the nutrition quality of adult food as inputs and returns the number of eggs in gen t+1 as output.\n",
    "\n",
    "Args: \n",
    "    numadult (int): number of adults in generation t\n",
    "    size_female_arr (array): size distribution of females in generation t\n",
    "    adnut (float): adult food nutrition quality\n",
    "\n",
    "Returns:\n",
    "    numegg (int): number of eggs in generation t+1\n",
    "\"\"\"\n",
    "    addens_ind_fec_arr = adnut*x5*np.log(x6+sen_adsize*size_female_arr)\n",
    "    addens_eff = 1/(1+sen_adden*numadult)\n",
    "    fecundity_arr = addens_eff*addens_ind_fec_arr\n",
    "    fecundity_arr = fecundity_arr.astype(int)\n",
    "    numegg = fecundity_arr.sum()\n",
    "    return numegg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adult-Module_which_explicitly takes in sen_adden and sen_adsize as inputs\n",
    "#adnut = #adult food nutrition quality; 1 (LL and HL), 1.29 (HH) and 1.49 (LH)\n",
    "\n",
    "def Adult_Module_with_sens_inputs(numadult, size_female_arr,adnut, sen_adden_val, sen_adsize_val):\n",
    "    \"\"\"  \n",
    "This function takes the number of adults in gen t, the female size distribution and the nutrition quality of adult food as inputs and returns the number of eggs in gen t+1 as output.\n",
    "\n",
    "Args: \n",
    "    numadult (int): number of adults in generation t\n",
    "    size_female_arr (array): size distribution of females in generation t\n",
    "    adnut (float): adult food nutrition quality\n",
    "\n",
    "Returns:\n",
    "    numegg (int): number of eggs in generation t+1\n",
    "\"\"\"\n",
    "    addens_ind_fec_arr = adnut*x5*np.log(x6+sen_adsize_val*size_female_arr)\n",
    "    addens_eff = 1/(1+sen_adden_val*numadult)\n",
    "    fecundity_arr = addens_eff*addens_ind_fec_arr\n",
    "    fecundity_arr = fecundity_arr.astype(int)\n",
    "    numegg = fecundity_arr.sum()\n",
    "    return numegg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Metapop_Simulation\n",
    "\n",
    "def Metapop_Simulation(numegg1_start,food1,adnut1,numegg2_start,food2,adnut2,generations,replicates):\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"  \n",
    "This function takes the number of eggs in gen 1, food amount provided to the larvae in each of the successive gens,\n",
    "the adult food nutrition quality in each of the successive gens for each subpopulation, \n",
    "number of generations for which each simulation will be run and the number of replicate simulations \n",
    "that will be run as inputs and returns a matrix of adult population sizes for each generation \n",
    "(each column is a replicate simulation and each row is a generation), a matrix of number of \n",
    "eggs in each generation and a matrix of extinctions for each replicate for both the subpopulations\n",
    "\n",
    "Args: \n",
    "    numegg1_start (int): number of eggs in generation 1 for patch 1\n",
    "    food1 (float): larval food amount in ml for patch 1\n",
    "    adnut1 (float): adult food nutrition quality for patch 1\n",
    "    numegg2_start (int): number of eggs in generation 1 for patch 2\n",
    "    food2 (float): larval food amount in ml for patch 2\n",
    "    adnut2 (float): adult food nutrition quality for patch 2\n",
    "    generations (int): number of generations for which each simulation will be run\n",
    "    replicates (int): number of replicate simulations that will be run\n",
    "\n",
    "Returns:\n",
    "    numadult_matrix1 (array): array of adult population sizes for each generation \n",
    "    (each column is a replicate simulation and each row is a generation) for patch 1\n",
    "    numegg_matrix1 (array): array of number of eggs in each generation for patch 1\n",
    "    extinctions_matrix1 (array): array of extinctions for each generation {1 if extinction happens and 0 otherwise} \n",
    "    (each column is a replicate simulation and each row is a generation) for patch 1\n",
    "    numadult_matrix2 (array): array of adult population sizes for each generation for patch 2\n",
    "    numegg_matrix2 (array): array of number of eggs in each generation for patch 2\n",
    "    extinctions_matrix2 (array): array of extinctions for each generation for patch 2\n",
    "\"\"\"\n",
    "    numadult_matrix1 = np.zeros((generations,replicates)) #array to store the number of adults per generation (patch 1 matrix -reach cokun s a repicae \n",
    "    numegg_matrix1 = np.zeros((generations,replicates)) #array to store the number of eggs per generation         \n",
    "    extinctions_matrix1 = np.zeros((generations,replicates)) #array denoting if extinction happened in any given gen \n",
    "    numadult_matrix2 = np.zeros((generations,replicates))  #patch 2 matrix is simula r\n",
    "    numegg_matrix2 = np.zeros((generations,replicates))\n",
    "    extinctions_matrix2 = np.zeros((generations,replicates))\n",
    "\n",
    "    print(sen_adden)\n",
    "\n",
    "    for i in range(replicates):\n",
    "        # 1st generation, we start with numegg1_start and numegg2_start eggs respectively   \n",
    "        numegg1 = numegg1_start  \n",
    "        numegg2 = numegg2_start\n",
    "        numegg_matrix1[0,i] = numegg1 \n",
    "        numegg_matrix2[0,i] = numegg2\n",
    "        numadult1, size_adult_arr1 = Pre_Adult_Module(numegg1,food1)\n",
    "        #print(numadult1)\n",
    "        numadult2, size_adult_arr2 = Pre_Adult_Module(numegg2,food2)\n",
    "        #print(numadult2)\n",
    "        numadult1,size_adult_arr1 = Demo_Stoch(numadult1,size_adult_arr1) #Where to put demo stoch?\n",
    "        numadult2,size_adult_arr2  = Demo_Stoch(numadult2,size_adult_arr2) \n",
    "        #print(numadult1,numadult2)\n",
    "        size_female_arr1 = Female_Size(size_adult_arr1)   \n",
    "        #print(size_female_arr1)\n",
    "        size_female_arr2 = Female_Size(size_adult_arr2)\n",
    "        #print(size_adult_arr2)\n",
    "        if numadult1 == 0 and numadult2 > 0:\n",
    "            extinctions_matrix1[0,i] = 1\n",
    "            numadult_matrix1[0,i] = numadult1\n",
    "            numadult_matrix2[0,i] = numadult2\n",
    "        elif numadult1 > 0 and numadult2 == 0:\n",
    "            extinctions_matrix2[0,i] = 1\n",
    "            numadult_matrix1[0,i] = numadult1\n",
    "            numadult_matrix2[0,i] = numadult2\n",
    "        elif numadult1 == 0 and numadult2 == 0: \n",
    "            numadult_matrix1[0,i] = 8 \n",
    "            numadult_matrix2[0,i] = 8\n",
    "            extinctions_matrix1[0,i] = 1\n",
    "            extinctions_matrix2[0,i] = 1 \n",
    "        else:\n",
    "            numadult_matrix1[0,i] = numadult1\n",
    "            numadult_matrix2[0,i] = numadult2\n",
    "        numadult1,numadult2,size_female_arr1,size_female_arr2 = Metapopulation_Reset(numadult1,numadult2,size_female_arr1,size_female_arr2)\n",
    "        #print(numadult1,numadult2)\n",
    "        numadult1,numadult2,size_female_arr1,size_female_arr2 = Migration(numadult1,numadult2,size_female_arr1,size_female_arr2)\n",
    "\n",
    "        for j in range(1,generations):\n",
    "            numegg1 = Adult_Module(numadult1,size_female_arr1,adnut1)\n",
    "            numegg2 = Adult_Module(numadult2,size_female_arr2,adnut2)\n",
    "            numegg_matrix1[j,i] = numegg1\n",
    "            numegg_matrix2[j,i] = numegg2\n",
    "            numadult1, size_adult_arr1 = Pre_Adult_Module(numegg1,food1)\n",
    "            numadult2, size_adult_arr2 = Pre_Adult_Module(numegg2,food2)\n",
    "            numadult1,size_adult_arr1 = Demo_Stoch(numadult1,size_adult_arr1)\n",
    "            numadult2,size_adult_arr2 = Demo_Stoch(numadult2,size_adult_arr2)\n",
    "            size_female_arr1 = Female_Size(size_adult_arr1)\n",
    "            size_female_arr2 = Female_Size(size_adult_arr2)\n",
    "            if numadult1 == 0 and numadult2 > 0:\n",
    "                extinctions_matrix1[j,i] = 1\n",
    "                numadult_matrix1[j,i] = numadult1\n",
    "                numadult_matrix2[j,i] = numadult2\n",
    "            elif numadult1 > 0 and numadult2 == 0:\n",
    "                extinctions_matrix2[j,i] = 1\n",
    "                numadult_matrix1[j,i] = numadult1\n",
    "                numadult_matrix2[j,i] = numadult2\n",
    "            elif numadult1 == 0 and numadult2 == 0: \n",
    "                numadult_matrix1[j,i] = 8\n",
    "                numadult_matrix2[j,i] = 8\n",
    "                extinctions_matrix1[j,i] = 1\n",
    "                extinctions_matrix2[j,i] = 1 \n",
    "            else:\n",
    "                numadult_matrix1[j,i] = numadult1\n",
    "                numadult_matrix2[j,i] = numadult2\n",
    "            numadult1,numadult2,size_female_arr1,size_female_arr2 = Metapopulation_Reset(numadult1,numadult2,size_female_arr1,size_female_arr2)\n",
    "            numadult1,numadult2,size_female_arr1,size_female_arr2 = Migration(numadult1,numadult2,size_female_arr1,size_female_arr2)\n",
    "    return numadult_matrix1,numegg_matrix1,extinctions_matrix1,numadult_matrix2,numegg_matrix2,extinctions_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Metapop_Simulation function food, adnut, sen_adden, sen_adsize, f as inputs\n",
    "\n",
    "def Metapop_Simulation_all_vars(numegg1_start,food1,adnut1,numegg2_start,food2,adnut2,generations,replicates, sen_adden_val, sen_adsize_val, f_val):\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"  \n",
    "This function takes the number of eggs in gen 1, food amount provided to the larvae in each of the successive gens,\n",
    "the adult food nutrition quality in each of the successive gens for each subpopulation, \n",
    "number of generations for which each simulation will be run and the number of replicate simulations \n",
    "that will be run as inputs and returns a matrix of adult population sizes for each generation \n",
    "(each column is a replicate simulation and each row is a generation), a matrix of number of \n",
    "eggs in each generation and a matrix of extinctions for each replicate for both the subpopulations\n",
    "\n",
    "Args: \n",
    "    numegg1_start (int): number of eggs in generation 1 for patch 1\n",
    "    food1 (float): larval food amount in ml for patch 1\n",
    "    adnut1 (float): adult food nutrition quality for patch 1\n",
    "    numegg2_start (int): number of eggs in generation 1 for patch 2\n",
    "    food2 (float): larval food amount in ml for patch 2\n",
    "    adnut2 (float): adult food nutrition quality for patch 2\n",
    "    generations (int): number of generations for which each simulation will be run\n",
    "    replicates (int): number of replicate simulations that will be run\n",
    "\n",
    "Returns:\n",
    "    numadult_matrix1 (array): array of adult population sizes for each generation \n",
    "    (each column is a replicate simulation and each row is a generation) for patch 1\n",
    "    numegg_matrix1 (array): array of number of eggs in each generation for patch 1\n",
    "    extinctions_matrix1 (array): array of extinctions for each generation {1 if extinction happens and 0 otherwise} \n",
    "    (each column is a replicate simulation and each row is a generation) for patch 1\n",
    "    numadult_matrix2 (array): array of adult population sizes for each generation for patch 2\n",
    "    numegg_matrix2 (array): array of number of eggs in each generation for patch 2\n",
    "    extinctions_matrix2 (array): array of extinctions for each generation for patch 2\n",
    "\"\"\"\n",
    "    numadult_matrix1 = np.zeros((generations,replicates)) #array to store the number of adults per generation (patch 1 matrix -reach cokun s a repicae \n",
    "    numegg_matrix1 = np.zeros((generations,replicates)) #array to store the number of eggs per generation         \n",
    "    extinctions_matrix1 = np.zeros((generations,replicates)) #array denoting if extinction happened in any given gen \n",
    "    numadult_matrix2 = np.zeros((generations,replicates))  #patch 2 matrix is simula r\n",
    "    numegg_matrix2 = np.zeros((generations,replicates))\n",
    "    extinctions_matrix2 = np.zeros((generations,replicates))\n",
    "\n",
    "    for i in range(replicates):\n",
    "        # 1st generation, we start with numegg1_start and numegg2_start eggs respectively   \n",
    "        numegg1 = numegg1_start  \n",
    "        numegg2 = numegg2_start\n",
    "        numegg_matrix1[0,i] = numegg1 \n",
    "        numegg_matrix2[0,i] = numegg2\n",
    "        numadult1, size_adult_arr1 = Pre_Adult_Module(numegg1,food1)\n",
    "        #print(numadult1)\n",
    "        numadult2, size_adult_arr2 = Pre_Adult_Module(numegg2,food2)\n",
    "        #print(numadult2)\n",
    "        numadult1,size_adult_arr1 = Demo_Stoch(numadult1,size_adult_arr1) #Where to put demo stoch?\n",
    "        numadult2,size_adult_arr2  = Demo_Stoch(numadult2,size_adult_arr2) \n",
    "        #print(numadult1,numadult2)\n",
    "        size_female_arr1 = Female_Size(size_adult_arr1)   \n",
    "        #print(size_female_arr1)\n",
    "        size_female_arr2 = Female_Size(size_adult_arr2)\n",
    "        #print(size_adult_arr2)\n",
    "        if numadult1 == 0 and numadult2 > 0:\n",
    "            extinctions_matrix1[0,i] = 1\n",
    "            numadult_matrix1[0,i] = numadult1\n",
    "            numadult_matrix2[0,i] = numadult2\n",
    "        elif numadult1 > 0 and numadult2 == 0:\n",
    "            extinctions_matrix2[0,i] = 1\n",
    "            numadult_matrix1[0,i] = numadult1\n",
    "            numadult_matrix2[0,i] = numadult2\n",
    "        elif numadult1 == 0 and numadult2 == 0: \n",
    "            numadult_matrix1[0,i] = 8 \n",
    "            numadult_matrix2[0,i] = 8\n",
    "            extinctions_matrix1[0,i] = 1\n",
    "            extinctions_matrix2[0,i] = 1 \n",
    "        else:\n",
    "            numadult_matrix1[0,i] = numadult1\n",
    "            numadult_matrix2[0,i] = numadult2\n",
    "        numadult1,numadult2,size_female_arr1,size_female_arr2 = Metapopulation_Reset(numadult1,numadult2,size_female_arr1,size_female_arr2)\n",
    "        #print(numadult1,numadult2)\n",
    "        numadult1,numadult2,size_female_arr1,size_female_arr2 = Migration_with_f(numadult1,numadult2,size_female_arr1,size_female_arr2, f_val)\n",
    "\n",
    "        for j in range(1,generations):\n",
    "            numegg1 = Adult_Module_with_sens_inputs(numadult1,size_female_arr1,adnut1, sen_adden_val, sen_adsize_val)\n",
    "            numegg2 = Adult_Module_with_sens_inputs(numadult2,size_female_arr2,adnut2, sen_adden_val, sen_adsize_val)\n",
    "            numegg_matrix1[j,i] = numegg1\n",
    "            numegg_matrix2[j,i] = numegg2\n",
    "            numadult1, size_adult_arr1 = Pre_Adult_Module(numegg1,food1)\n",
    "            numadult2, size_adult_arr2 = Pre_Adult_Module(numegg2,food2)\n",
    "            numadult1,size_adult_arr1 = Demo_Stoch(numadult1,size_adult_arr1)\n",
    "            numadult2,size_adult_arr2 = Demo_Stoch(numadult2,size_adult_arr2)\n",
    "            size_female_arr1 = Female_Size(size_adult_arr1)\n",
    "            size_female_arr2 = Female_Size(size_adult_arr2)\n",
    "            if numadult1 == 0 and numadult2 > 0:\n",
    "                extinctions_matrix1[j,i] = 1\n",
    "                numadult_matrix1[j,i] = numadult1\n",
    "                numadult_matrix2[j,i] = numadult2\n",
    "            elif numadult1 > 0 and numadult2 == 0:\n",
    "                extinctions_matrix2[j,i] = 1\n",
    "                numadult_matrix1[j,i] = numadult1\n",
    "                numadult_matrix2[j,i] = numadult2\n",
    "            elif numadult1 == 0 and numadult2 == 0: \n",
    "                numadult_matrix1[j,i] = 8\n",
    "                numadult_matrix2[j,i] = 8\n",
    "                extinctions_matrix1[j,i] = 1\n",
    "                extinctions_matrix2[j,i] = 1 \n",
    "            else:\n",
    "                numadult_matrix1[j,i] = numadult1\n",
    "                numadult_matrix2[j,i] = numadult2\n",
    "            numadult1,numadult2,size_female_arr1,size_female_arr2 = Metapopulation_Reset(numadult1,numadult2,size_female_arr1,size_female_arr2)\n",
    "            numadult1,numadult2,size_female_arr1,size_female_arr2 = Migration_with_f(numadult1,numadult2,size_female_arr1,size_female_arr2, f_val)\n",
    "    return numadult_matrix1,numegg_matrix1,extinctions_matrix1,numadult_matrix2,numegg_matrix2,extinctions_matrix2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metapop_matrices\n",
    "\n",
    "def Metapop_numegg_matrix(numegg_matrix1,numegg_matrix2):\n",
    "    \"\"\"\n",
    "This function takes the numegg_matrix of both patches as inputs and returns the numegg_matrix of the metapopulation as output.\n",
    "\n",
    "Args:\n",
    "    numegg_matrix1 (array): array of number of eggs in each generation (patch 1)\n",
    "    numegg_matrix2 (array): array of number of eggs in each generation (patch 2)\n",
    "\n",
    "Returns:\n",
    "    numadult_matrix (array): array of number of eggs in each generation (metapopulation)\n",
    "\"\"\"\n",
    "    numegg_matrix = numegg_matrix1 + numegg_matrix2\n",
    "    return numegg_matrix\n",
    "\n",
    "\n",
    "\n",
    "def Metapop_numadult_matrix(numadult_matrix1,numadult_matrix2):\n",
    "    \"\"\"\n",
    "This function takes the numadult_matrix of both patches as inputs and returns the numadult_matrix of the metapopulation as output.\n",
    "\n",
    "Args:\n",
    "    numadult_matrix1 (array): array of adult population sizes for each generation (patch 1)\n",
    "    numadult_matrix2 (array): array of adult population sizes for each generation (patch 2)\n",
    "\n",
    "Returns:\n",
    "    numadult_matrix (array): array of adult population sizes for each generation (metapopulation)\n",
    "\"\"\"\n",
    "    numadult_matrix = numadult_matrix1 + numadult_matrix2\n",
    "    return numadult_matrix\n",
    "\n",
    "\n",
    "def Metapop_extinctions_matrix(extinctions_matrix1,extinctions_matrix2):\n",
    "    \"\"\"\n",
    "This function takes the extinctions_matrix of both patches as inputs and returns the extinctions_matrix of the metapopulation as output.\n",
    "\n",
    "Args:\n",
    "    extinctions_matrix1 (array): array of extinctions for each generation (patch 1)\n",
    "    extinctions_matrix2 (array): array of extinctions for each generation (patch 2)\n",
    "\n",
    "Returns:\n",
    "    extinctions_matrix (array): array of extinctions for each generation (metapopulation)\n",
    "\"\"\"\n",
    "    extinctions_matrix = extinctions_matrix1 + extinctions_matrix2\n",
    "    extinctions_matrix = extinctions_matrix/2\n",
    "    extinctions_matrix[extinctions_matrix < 1] = 0\n",
    "    return extinctions_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_extinction_n\n",
    "\n",
    "def prob_extinction_n(extinctions_matrix,n):\n",
    "    \"\"\"  \n",
    "This function takes the extinctions_matrix, and n (number of generations) as input and returns the probability of extinction happening in the first n generations\n",
    "\n",
    "Args: \n",
    "    extinctions_matrix (array): array of extinctions for each generation {1 if extinction happens and 0 otherwise} (each column is a replicate simulation and each row is a generation)\n",
    "    n (int): first n number of generations   \n",
    "\n",
    "Returns:\n",
    "    prob (0 <= float <= 1): rel. freq of replicates in which we did observe an extinction by the nth generation\n",
    "\"\"\"\n",
    "    if extinctions_matrix.ndim == 1:\n",
    "        extinctions_matrix = np.expand_dims(extinctions_matrix, axis=1)\n",
    "    replicates = np.shape(extinctions_matrix)[1]\n",
    "    col_sum  = extinctions_matrix[0:n,:].sum(axis=0) \n",
    "    extinc_repl = (col_sum>=1).sum()\n",
    "    prob = extinc_repl/replicates\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch_extinction_freq \n",
    "\n",
    "def Patch_extinction_freq(extinctions_matrix_1,extinctions_matrix_2):\n",
    "    \"\"\"\n",
    "This function takes the extinctions_matrix of both the patches as inputs and returns the extinction frequency of the two patches (average over all replicates)\n",
    "\n",
    "Args:\n",
    "    extinctions_matrix_1 (matrix) : patch 1 extinctions matrix; rows are generations and columns are replicates \n",
    "    extinctions_matrix_2 (matrix) : patch 2 extinctions matrix; rows are generations and columns are replicates\n",
    "\n",
    "Returns:\n",
    "    extinc_freq_mean_1 (float): Avg Extinction frequency (i.e. number of times extinction happened/number of generations) of all replicates (patch 1)\n",
    "    extinc_freq_std_1 (float): Std dev of Extinction frequency across replicates (patch 1)\n",
    "    extinc_freq_mean_2 (float): Avg Extinction frequency (i.e. number of times extinction happened/number of generations) of all replicates (patch 2)\n",
    "    extinc_freq_std_2 (float): Std dev of Extinction frequency across replicates (patch 2)\n",
    "\n",
    "\"\"\"\n",
    "    reps = np.shape(extinctions_matrix_1)[1] # = np.shape(extinctions_matrix_2)[1] number of replicates\n",
    "    gens = np.shape(extinctions_matrix_1)[0] # = np.shape(extinctions_matrix_2)[0] number of generations\n",
    "    patch_1_reps_extinctions = np.zeros(reps) #array to store the extinction frequency for each replicate\n",
    "    patch_2_reps_extinctions = np.zeros(reps)\n",
    "    for i in range(reps):\n",
    "        ts1 = extinctions_matrix_1[:,i] #time series of extinctions for each replicate\n",
    "        ts2 = extinctions_matrix_2[:,i]\n",
    "        extinctions_1 = 0\n",
    "        extinctions_2 = 0\n",
    "        for j in range(gens):\n",
    "            # if a consecutive series of 1s is found in only one patch and other patch doesn't have extinctions, then it is counted as one extinction event in the patch that has extinctions\n",
    "            # if both patches have consecutive simulataneous extinctions, then it is counted as more than one extinction event as patches get reset after each simultaneous extinction event\n",
    "            if ts1[j] == 1 and  ts1[j-1] == 0: #no extinction in patch 1 in the previous gen\n",
    "                extinctions_1 += 1\n",
    "            elif ts1[j] == 1 and ts1[j-1] == 1 and ts2[j-1]==1: # simultaneous extinction in both patches in the previous gen \n",
    "                extinctions_1 += 1\n",
    "            \n",
    "            if ts2[j] == 1 and  ts2[j-1] == 0: #no extinction in patch 2 in the previous gen\n",
    "                extinctions_2 += 1\n",
    "            elif ts2[j] == 1 and ts2[j-1] == 1 and ts1[j-1]==1: # simultaneous extinction in both patches in the previous gen\n",
    "                extinctions_2 += 1\n",
    "        patch_1_reps_extinctions[i] = extinctions_1/gens #extinction frequency for each replicate\n",
    "        patch_2_reps_extinctions[i] = extinctions_2/gens #extinction frequency for each replicate\n",
    "    extinc_freq_mean_1 = np.mean(patch_1_reps_extinctions) #mean extinction frequency across replicates\n",
    "    extinc_freq_std_1 = np.std(patch_1_reps_extinctions) #std dev of extinction frequency across replicates\n",
    "    extinc_freq_mean_2 = np.mean(patch_2_reps_extinctions) #mean extinction frequency across replicates\n",
    "    extinc_freq_std_2 = np.std(patch_2_reps_extinctions) #std dev of extinction frequency across replicates\n",
    "    return extinc_freq_mean_1, extinc_freq_std_1, extinc_freq_mean_2, extinc_freq_std_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metapop_extinction_freq\n",
    "\n",
    "def metapop_extinc_freq(metapop_extinctions_matrix):\n",
    "    \"\"\"This function takes the metapopulation extinctions_matrix as input and returns the extinction frequency (average over all replicates))\n",
    "\n",
    "Args:\n",
    "    metapop_extinctions_matrix (matrix) : metapopulation extinctions matrix; \n",
    "    \n",
    "Returns:\n",
    "    metapop_extinc_freq_mean (float): Avg Extinction frequency (i.e. number of times extinction happened/number of generations) of all replicates \n",
    "    metapop_extinc_freq_std (float): Std dev of Extinction frequency across replicates\"\"\"\n",
    "    #reps = np.shape(metapop_extinctions_matrix)[1] #number of replicates\n",
    "    #gens = np.shape(metapop_extinctions_matrix)[0] #number of generations\n",
    "    metapop_reps_extinctions = np.sum(metapop_extinctions_matrix,axis=0) #array to store the extinction frequency for each replicate\n",
    "    metapop_reps_extinctions = metapop_reps_extinctions/np.shape(metapop_extinctions_matrix)[0] #extinction frequency for each replicate\n",
    "    metapop_extinc_freq_mean = np.mean(metapop_reps_extinctions) #mean extinction frequency across replicates\n",
    "    metapop_extinc_freq_std = np.std(metapop_reps_extinctions) #std dev of extinction frequency across replicates\n",
    "    return metapop_extinc_freq_mean, metapop_extinc_freq_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Converting time series data to find correlations\n",
    "\n",
    "\n",
    "def log_diff(numadult_matrix):\n",
    "    \"\"\"This function takes the numadult_matrix as input and for each time series find the first lag 0 differences of log transformed data and return the transformed data\n",
    "\n",
    "Args:\n",
    "    numadult_matrix (array): array of adult population sizes for each generation \n",
    "    \n",
    "Returns:\n",
    "    numadult_matrix (array): array of adult population sizes for each generation after transformation\"\"\" \n",
    "    # make sure that the zero values are replaced by extremely small values\n",
    "    numadult_matrix[numadult_matrix == 0] = 1e-4\n",
    "    numadult_matrix = np.log(numadult_matrix)\n",
    "    numadult_matrix = np.diff(numadult_matrix,axis=0)\n",
    "    return numadult_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Pearson Corellation between replicate simulations. To check if there is enough stochasticity in the simulations\n",
    "\n",
    "\n",
    "def Pearson_corr_replicates_FT(numadult_matrix):\n",
    "    \"\"\"This function takes the numadult_matrix as input and returns the Pearson correlation between all possible pairs of replicate simulations\n",
    "    (Involves using Fisher transformation)\n",
    "\n",
    "Args:\n",
    "    numadult_matrix (array): array of adult population sizes for each generation \n",
    "    \n",
    "Returns:\n",
    "    corr (float): average Pearson correlation between the replicate simulations\"\"\"\n",
    "\n",
    "    if numadult_matrix.ndim == 1:\n",
    "        numadult_matrix = np.expand_dims(numadult_matrix,axis=1)\n",
    "    corr = np.corrcoef(numadult_matrix,rowvar=False) #rowvar=False because each column is a time series\n",
    "    mean_corr = 0\n",
    "    for i in range(np.shape(corr)[0]-1):\n",
    "        mean_corr = mean_corr + np.mean(np.arctanh(corr[i,i+1:])) #sum of the Fisher transformed correlations \n",
    "                                                        #between all the possible combinations of replicate simulations\n",
    "                                                        #We only take the upper triangular part of the matrix leaving out the diagonal\n",
    "    rep_combn_number = len(list(it.combinations(range(np.shape(corr)[0]),2))) #number of possible combinations of replicate simulations\n",
    "    mean_corr = mean_corr/rep_combn_number #average of the correlations between all the possible combinations of replicate simulations\n",
    "    mean_corr = np.tanh(mean_corr) #inverse fisher transformation; this is the average correlation between the replicate simulations\n",
    "    return mean_corr\n",
    "\n",
    "def Pearson_corr_replicates(numadult_matrix):\n",
    "    \"\"\"This function takes the numadult_matrix as input and returns the Pearson correlation between all possible pairs of replicate simulations\n",
    "\n",
    "Args:\n",
    "    numadult_matrix (array): array of adult population sizes for each generation \n",
    "    \n",
    "Returns:\n",
    "    corr (float): average Pearson correlation between the replicate simulations\"\"\"\n",
    "\n",
    "    if numadult_matrix.ndim == 1:\n",
    "        numadult_matrix = np.expand_dims(numadult_matrix,axis=1)\n",
    "    corr = np.corrcoef(numadult_matrix,rowvar=False) #rowvar=False because each column is a time series\n",
    "    mean_corr = 0\n",
    "    for i in range(np.shape(corr)[0]-1):\n",
    "        mean_corr = mean_corr + np.mean(corr[i,i+1:]) #sum of the correlations \n",
    "                                                        #between all the possible combinations of replicate simulations\n",
    "                                                        #We only take the upper triangular part of the matrix leaving out the diagonal\n",
    "    rep_combn_number = len(list(it.combinations(range(np.shape(corr)[0]),2))) #number of possible combinations of replicate simulations\n",
    "    mean_corr = mean_corr/rep_combn_number #average of the correlations between all the possible combinations of replicate simulations\n",
    "    #mean_corr = np.tanh(mean_corr) #inverse fisher transformation; this is the average correlation between the replicate simulations\n",
    "    return mean_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pearson Corellation between the two patches\n",
    "\n",
    "\n",
    "def Pearson_corr_patches_FT(numadult_matrix1,numadult_matrix2):\n",
    "    \"\"\"This function takes the numadult_matrix1 and numadult_matrix2 as input and returns the average Pearson correlation between the two patches\n",
    "    (Involves using Fisher transformation)\n",
    "Args:\n",
    "    numadult_matrix1 (array): array of adult population sizes (log transformed first lag 1 difference) for each generation (patch 1)\n",
    "    numadult_matrix2 (array): array of adult population sizes (log transformed first lag 1 difference) for each generation (patch 2)\n",
    "    \n",
    "Returns:\n",
    "    corr (float): average Pearson correlation between the two patches\"\"\"\n",
    "    if numadult_matrix1.ndim == 1:\n",
    "        numadult_matrix1 = np.expand_dims(numadult_matrix1,axis=1)\n",
    "    if numadult_matrix2.ndim == 1:\n",
    "        numadult_matrix2 = np.expand_dims(numadult_matrix2,axis=1)\n",
    "    corr_rep_array = []\n",
    "    for i in range(np.shape(numadult_matrix1)[1]):\n",
    "        corr = np.corrcoef(numadult_matrix1[:,i],numadult_matrix2[:,i],rowvar=False)\n",
    "        corr = corr[0,1]\n",
    "        corr_rep_array.append(corr)\n",
    "    corr_rep_array = np.array(corr_rep_array)\n",
    "    #print(corr_rep_array)\n",
    "    corr_rep_array = np.arctanh(corr_rep_array) #fisher transformation\n",
    "    corr = np.mean(corr_rep_array) #mean of the fisher transformed correlation matrix\n",
    "    corr = np.tanh(corr) #inverse fisher transformation; this is the average correlation between the two patches\n",
    "    return corr\n",
    "\n",
    "\n",
    "\n",
    "def Pearson_corr_patches(numadult_matrix1,numadult_matrix2):\n",
    "    \"\"\"This function takes the numadult_matrix1 and numadult_matrix2 as input and returns the average Pearson correlation between the two patches\n",
    "Args:\n",
    "    numadult_matrix1 (array): array of adult population sizes (log transformed first lag 1 difference) for each generation (patch 1)\n",
    "    numadult_matrix2 (array): array of adult population sizes (log transformed first lag 1 difference) for each generation (patch 2)\n",
    "    \n",
    "Returns:\n",
    "    corr (float): average Pearson correlation between the two patches\"\"\"\n",
    "    if numadult_matrix1.ndim == 1:\n",
    "        numadult_matrix1 = np.expand_dims(numadult_matrix1,axis=1)\n",
    "    if numadult_matrix2.ndim == 1:\n",
    "        numadult_matrix2 = np.expand_dims(numadult_matrix2,axis=1)\n",
    "    corr_rep_array = []\n",
    "    for i in range(np.shape(numadult_matrix1)[1]):\n",
    "        corr = np.corrcoef(numadult_matrix1[:,i],numadult_matrix2[:,i],rowvar=False)\n",
    "        corr = corr[0,1]\n",
    "        corr_rep_array.append(corr)\n",
    "    corr_rep_array = np.array(corr_rep_array)\n",
    "    #print(corr_rep_array)\n",
    "    #corr_rep_array = np.arctanh(corr_rep_array) #fisher transformation\n",
    "    corr = np.mean(corr_rep_array) #mean of the fisher transformed correlation matrix\n",
    "    #corr = np.tanh(corr) #inverse fisher transformation; this is the average correlation between the two patches\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spearman Corellation between replicate simulations\n",
    "\n",
    "\n",
    "def Spearman_corr_replicates_FT(numadult_matrix):\n",
    "    \"\"\"This function takes the numadult_matrix as input and returns the Spearman correlation between all possible pairs of replicate simulations\n",
    "(Involves using Fisher transformation)\n",
    "    \n",
    "Args:\n",
    "    numadult_matrix (array): array of adult population sizes for each generation \n",
    "    \n",
    "Returns:\n",
    "    corr (float): average Spearman correlation between the replicate simulations\"\"\"\n",
    "\n",
    "    if numadult_matrix1.ndim == 1:\n",
    "        numadult_matrix1 = np.expand_dims(numadult_matrix1,axis=1)\n",
    "    #if numadult_matrix2.ndim == 1:\n",
    "    #    numadult_matrix2 = np.expand_dims(numadult_matrix2,axis=1)\n",
    "    cols = np.shape(numadult_matrix)[1]\n",
    "    col_combns = list(it.combinations(range(cols),2)) #all possible combinations of columns\n",
    "    corr_rep_array = []\n",
    "    for i in range(len(col_combns)):\n",
    "        corr = stats.spearmanr(numadult_matrix[:,col_combns[i][0]],numadult_matrix[:,col_combns[i][1]]).correlation\n",
    "        corr_rep_array.append(corr)\n",
    "    corr_rep_array = np.array(corr_rep_array)\n",
    "    corr_rep_array = np.arctanh(corr_rep_array) #fisher transformation\n",
    "    avg_corr = np.mean(corr_rep_array) #mean of the fisher transformed correlation matrix\n",
    "    avg_corr = np.tanh(avg_corr) #inverse fisher transformation; this is the average correlation between the replicate simulations\n",
    "    return avg_corr\n",
    "\n",
    "def Spearman_corr_replicates(numadult_matrix):\n",
    "    \"\"\"This function takes the numadult_matrix as input and returns the Spearman correlation between all possible pairs of replicate simulations\n",
    "    \n",
    "Args:\n",
    "    numadult_matrix (array): array of adult population sizes for each generation \n",
    "    \n",
    "Returns:\n",
    "    corr (float): average Spearman correlation between the replicate simulations\"\"\"\n",
    "\n",
    "    if numadult_matrix1.ndim == 1:\n",
    "        numadult_matrix1 = np.expand_dims(numadult_matrix1,axis=1)\n",
    "    #if numadult_matrix2.ndim == 1:\n",
    "    #    numadult_matrix2 = np.expand_dims(numadult_matrix2,axis=1)\n",
    "    cols = np.shape(numadult_matrix)[1]\n",
    "    col_combns = list(it.combinations(range(cols),2)) #all possible combinations of columns\n",
    "    corr_rep_array = []\n",
    "    for i in range(len(col_combns)):\n",
    "        corr = stats.spearmanr(numadult_matrix[:,col_combns[i][0]],numadult_matrix[:,col_combns[i][1]]).correlation\n",
    "        corr_rep_array.append(corr)\n",
    "    corr_rep_array = np.array(corr_rep_array)\n",
    "    #corr_rep_array = np.arctanh(corr_rep_array) #fisher transformation\n",
    "    avg_corr = np.mean(corr_rep_array) #mean of the fisher transformed correlation matrix\n",
    "    #avg_corr = np.tanh(avg_corr) #inverse fisher transformation; this is the average correlation between the replicate simulations\n",
    "    return avg_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Spearman Corellation between the two patches\n",
    "\n",
    "\n",
    "def Spearman_corr_patches_FT(numadult_matrix1,numadult_matrix2):\n",
    "    \"\"\"This function takes the numadult_matrix1 and numadult_matrix2 as input and returns the average Spearman correlation between the two patches\n",
    "(Involves using Fisher transformation)\n",
    "    \n",
    "Args:\n",
    "    numadult_matrix1 (array): array of adult population sizes for each generation (patch 1)\n",
    "    numadult_matrix2 (array): array of adult population sizes for each generation (patch 2)\n",
    "    \n",
    "Returns:\n",
    "    corr (float): average Spearman correlation between the two patches\"\"\" \n",
    "\n",
    "    if numadult_matrix1.ndim == 1:\n",
    "        numadult_matrix1 = np.expand_dims(numadult_matrix1,axis=1)\n",
    "    if numadult_matrix2.ndim == 1:\n",
    "        numadult_matrix2 = np.expand_dims(numadult_matrix2,axis=1)\n",
    "    corr_rep_array = []\n",
    "    for i in range(np.shape(numadult_matrix1)[1]):\n",
    "        corr = stats.spearmanr(numadult_matrix1[:,i],numadult_matrix2[:,i]).correlation\n",
    "        corr_rep_array.append(corr)\n",
    "    corr_rep_array = np.array(corr_rep_array)\n",
    "    corr_rep_array = np.arctanh(corr_rep_array) #fisher transformation\n",
    "    corr = np.mean(corr_rep_array) #mean of the fisher transformed correlation matrix\n",
    "    corr = np.tanh(corr) #inverse fisher transformation; this is the average correlation between the two patches\n",
    "    return corr        \n",
    "        \n",
    "def Spearman_corr_patches(numadult_matrix1,numadult_matrix2):\n",
    "    \"\"\"This function takes the numadult_matrix1 and numadult_matrix2 as input and returns the average Spearman correlation between the two patches\n",
    "    \n",
    "Args:\n",
    "    numadult_matrix1 (array): array of adult population sizes for each generation (patch 1)\n",
    "    numadult_matrix2 (array): array of adult population sizes for each generation (patch 2)\n",
    "    \n",
    "Returns:\n",
    "    corr (float): average Spearman correlation between the two patches\"\"\" \n",
    "\n",
    "    if numadult_matrix1.ndim == 1:\n",
    "        numadult_matrix1 = np.expand_dims(numadult_matrix1,axis=1)\n",
    "    if numadult_matrix2.ndim == 1:\n",
    "        numadult_matrix2 = np.expand_dims(numadult_matrix2,axis=1)\n",
    "    corr_rep_array = []\n",
    "    for i in range(np.shape(numadult_matrix1)[1]):\n",
    "        corr = stats.spearmanr(numadult_matrix1[:,i],numadult_matrix2[:,i]).correlation\n",
    "        corr_rep_array.append(corr)\n",
    "    corr_rep_array = np.array(corr_rep_array)\n",
    "    #corr_rep_array = np.arctanh(corr_rep_array) #fisher transformation\n",
    "    corr = np.mean(corr_rep_array) #mean of the fisher transformed correlation matrix\n",
    "    #corr = np.tanh(corr) #inverse fisher transformation; this is the average correlation between the two patches\n",
    "    return corr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fluc_Ind\n",
    "\n",
    "def Fluc_Ind(tim_ser):\n",
    "    \"\"\"  \n",
    "This function takes a time series (i.e. one of the columns of our numdult matrix) as input and returns the fluctuation index\n",
    "\n",
    "Args: \n",
    "    tim_ser (array) : array of population size (i.e. number of adults) in each generation  \n",
    "\n",
    "Returns:\n",
    "    FI (float): Fluctuation index of the time series\n",
    "\"\"\"\n",
    "    T = len(tim_ser)\n",
    "    Nbar = np.mean(tim_ser)\n",
    "    FI = 0 #initiate\n",
    "    for i in range(T-1):\n",
    "        FI += abs(tim_ser[i+1]-tim_ser[i])\n",
    "    FI = FI/(T*Nbar)\n",
    "    return FI\n",
    "\n",
    "\n",
    "# FI_numadult_matrix\n",
    "\n",
    "def FI_numadult_matrix(numadult_matrix):\n",
    "    \"\"\"  \n",
    "This function takes numadult_matrix as input and returns the mean and sd of FI across all replicates\n",
    "\n",
    "Args: \n",
    "    numadult_matrix (array): array of adult population sizes for each generation   \n",
    "\n",
    "Returns:\n",
    "    FI_mean (float): Mean fluctuation index of all replicates\n",
    "    FI_sd (float): Sd fluctuation index of all replicates\n",
    "\"\"\"\n",
    "    # FI for each replicate; if only one replicate, then np.shape(numadult_matrix)[1] = 1\n",
    "    #numadult_matrix = np.expand_dims(numadult_matrix,axis=1) # so that even single replicate is treated as a matrix\n",
    "    if numadult_matrix.ndim == 1:\n",
    "        numadult_matrix = np.expand_dims(numadult_matrix,axis=1)\n",
    "    FI_arr = np.zeros(np.shape(numadult_matrix)[1])\n",
    "    for i in range(np.shape(numadult_matrix)[1]):\n",
    "        FI_arr[i] = Fluc_Ind(numadult_matrix[:,i])\n",
    "    FI_mean = np.mean(FI_arr)\n",
    "    FI_std = np.std(FI_arr)\n",
    "    return FI_mean, FI_std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "###Plotting\n",
    "##plot_time_series\n",
    "\n",
    "\n",
    "def plot_time_series(numadult_matrix1,numadult_matrix2,numadult_metapop_matrix,replicates):\n",
    "    \"\"\"\n",
    "This function takes numadult_matrix1, numadult_matrix2 , numadult_metapop_matrix and the list of replicates as input and plots the time series of population size for each replicate in the list\n",
    "\n",
    "Args:\n",
    "    numadult_matrix1 (array): array of adult population sizes for each generation (patch 1)\n",
    "    numadult_matrix2 (array): array of adult population sizes for each generation (patch 2)\n",
    "    numadult_metapop_matrix (array): array of adult population sizes for each generation (metapopulation)\n",
    "    replicates (list): list of replicates for which we want to plot the time series\n",
    "\n",
    "Returns:\n",
    "    None (plots the time series of population size for each replicate in the list)\n",
    "\"\"\"\n",
    "    for i in replicates:\n",
    "        plt.plot(numadult_matrix1[:,i])\n",
    "        plt.plot(numadult_matrix2[:,i])\n",
    "        plt.plot(numadult_metapop_matrix[:,i])\n",
    "        legend = [f'Patch_1_rep{i}',f'Patch_2_rep_{i}',f'Metapopulation_rep_{i}']\n",
    "        plt.legend(legend)\n",
    "    plt.xlabel('Generation')\n",
    "    plt.ylabel('Population size')\n",
    "    #plt.ylim(0,200)\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to read experimental data from excel sheet\n",
    "\n",
    "\n",
    "def extinctions_matrix_from_nadult_matrix(nadult_matrix1,nadult_matrix2):\n",
    "    \"\"\"This function takes nadult_matrix1 and nadult_matrix2 obtained from excel sheet as input and returns extincions_matrix1 and extinctions_matrix2\n",
    "\n",
    "Args:\n",
    "    nadult_matrix1 (array): array of adult population sizes for each generation (patch 1)\n",
    "    nadult_matrix2 (array): array of adult population sizes for each generation (patch 2)\n",
    "\n",
    "Returns:\n",
    "    extinctions_matrix1 (array): array of extinctions for each generation (patch 1)\n",
    "    extinctions_matrix2 (array): array of extinctions for each generation (patch 2)\"\"\"\n",
    "    if nadult_matrix1.ndim == 1:\n",
    "        nadult_matrix1 = np.expand_dims(nadult_matrix1,axis=1)\n",
    "    if nadult_matrix2.ndim == 1:\n",
    "        nadult_matrix2 = np.expand_dims(nadult_matrix2,axis=1)\n",
    "    reps = np.shape(nadult_matrix1)[1]\n",
    "    generations = np.shape(nadult_matrix1)[0]\n",
    "    extinctions_matrix1 = np.zeros([generations,reps])\n",
    "    extinctions_matrix2 = np.zeros([generations,reps])\n",
    "    for i in range(reps):\n",
    "        for j in range(generations):\n",
    "            if nadult_matrix1[j,i] == 0 and nadult_matrix2[j,i] > 0:\n",
    "                extinctions_matrix1[j,i] = 1\n",
    "            elif nadult_matrix1[j,i] > 0 and nadult_matrix2[j,i] == 0:\n",
    "                extinctions_matrix2[j,i] = 1\n",
    "            elif nadult_matrix1[j,i] == 8 and nadult_matrix2[j,i] == 8:\n",
    "                extinctions_matrix1[j,i] = 1\n",
    "                extinctions_matrix2[j,i] = 1\n",
    "    return extinctions_matrix1,extinctions_matrix2\n",
    "\n",
    "\n",
    "def patch_data(data):\n",
    "    \"\"\"This function takes the LHLH data from excel sheet (own modified sheet made from the original data) as input and returns nadult matrices, and extinction matrices for patch 1, patch 2 and metapopulation\n",
    "\n",
    "Args:\n",
    "    data (dataframe): dataframe containing the patch 1 and patch 2 data for LHLH population \n",
    "    \n",
    "Returns:\n",
    "    nadult_matrix1 (array): array of adult population sizes for each generation (patch 1)\n",
    "    nadult_matrix2 (array): array of adult population sizes for each generation (patch 2)\n",
    "    metapop_nadult_matrix (array): array of adult population sizes for each generation (metapopulation)\n",
    "    extinctions_matrix1 (array): array of extinctions for each generation (patch 1)\n",
    "    extinctions_matrix2 (array): array of extinctions for each generation (patch 2)\n",
    "    metapop_extinctions_matrix (array): array of extinctions for each generation (metapopulation)\"\"\"\n",
    "  \n",
    "    nadult_matrix1 = np.array(data.iloc[1:,0:4])  #nadult matrix patch 1 -so it is able to get thtt\n",
    "    nadult_matrix1 = nadult_matrix1.astype(float)\n",
    "    nadult_matrix2 = np.array(data.iloc[1:,6:10])  #\n",
    "    nadult_matrix2 = nadult_matrix2.astype(float)\n",
    "    metapop_nadult_matrix = Metapop_numadult_matrix(nadult_matrix1,nadult_matrix2) #adding patch 1 and patch 2\n",
    "    extinctions_matrix1,extinctions_matrix2 = extinctions_matrix_from_nadult_matrix(nadult_matrix1,nadult_matrix2)\n",
    "    metapop_extinctions_matrix = Metapop_extinctions_matrix(extinctions_matrix1,extinctions_matrix2)\n",
    "    return nadult_matrix1,nadult_matrix2,metapop_nadult_matrix,extinctions_matrix1,extinctions_matrix2,metapop_extinctions_matrix  #gives nadult matrix 1, nn n, ,etinyo jsn;t rwh. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV(numadult_matrix):\n",
    "    \"\"\"This function takes numadult_matrix as input and returns the mean and sd of the coefficient of variation (CV)\n",
    "\n",
    "Args:\n",
    "    numadult_matrix (array): array of adult population sizes for each generation\n",
    "\n",
    "Returns:\n",
    "    mean_CV (float): mean of the coefficient of variation (over all replicates)) \n",
    "    sd_CV (float): standard deviation of the coefficient of variation (over all replicates)\"\"\"\n",
    "    mean_CV = np.mean(np.std(numadult_matrix,axis=0)/np.mean(numadult_matrix,axis=0))\n",
    "    sd_CV = np.std(np.std(numadult_matrix,axis=0)/np.mean(numadult_matrix,axis=0))\n",
    "    return mean_CV,sd_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocrr_lag1(numadult_matrix):\n",
    "    \"\"\"This function takes numadult_matrix as input and returns the mean and sd of the autocorrelation lag 1\n",
    "\n",
    "    Args: numadult_matrix (array): array of adult population sizes for each generation\n",
    "\n",
    "    Returns:\n",
    "    mean_autocrr_lag1 (float): mean of the autocorrelation lag 1 (over all replicates)\n",
    "    sd_autocrr_lag1 (float): standard deviation of the autocorrelation lag 1 (over all replicates)\"\"\"\n",
    "\n",
    "\n",
    "    #numadult_matrixt = log_diff(numadult_matrix)\n",
    "    if numadult_matrix.ndim == 1:\n",
    "        numadult_matrix = np.expand_dims(numadult_matrix,axis=1)\n",
    "    reps = np.shape(numadult_matrix)[1]\n",
    "    gens = np.shape(numadult_matrix)[0]\n",
    "    autocrr_lag1_arr = np.zeros(reps) # array of autocorrelation lag 1 for each replicate\n",
    "    for i in range(reps):\n",
    "        s = pd.Series(numadult_matrix[:,i])\n",
    "        autocrr_lag1_arr[i] = s.autocorr(lag=1)\n",
    "        #autocrr_lag1_arr[i] = np.correlate(numadult_matrix[:,i],numadult_matrix[1:,i],\"full\")[gens - 1]\n",
    "    return np.mean(autocrr_lag1_arr), np.std(autocrr_lag1_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocrr_lag2(numadult_matrix):\n",
    "    \"\"\"This function takes numadult_matrix as input and returns the mean and sd of the autocorrelation lag 2\n",
    "\n",
    "    Args: numadult_matrix (array): array of adult population sizes for each generation\n",
    "\n",
    "    Returns:\n",
    "    mean_autocrr_lag2 (float): mean of the autocorrelation lag 2 (over all replicates)\n",
    "    sd_autocrr_lag2 (float): standard deviation of the autocorrelation lag 2 (over all replicates)\"\"\"\n",
    "\n",
    "\n",
    "    #numadult_matrixt = log_diff(numadult_matrix)\n",
    "    if numadult_matrix.ndim == 1:\n",
    "        numadult_matrix = np.expand_dims(numadult_matrix,axis=1)\n",
    "    reps = np.shape(numadult_matrix)[1]\n",
    "    gens = np.shape(numadult_matrix)[0]\n",
    "    autocrr_lag2_arr = np.zeros(reps) # array of autocorrelation lag 1 for each replicate\n",
    "    for i in range(reps):\n",
    "        s = pd.Series(numadult_matrix[:,i])\n",
    "        autocrr_lag2_arr[i] = s.autocorr(lag=2)\n",
    "        #autocrr_lag2_arr[i] = np.correlate(numadult_matrix[:,i],numadult_matrix[1:,i],\"full\")[gens + 1]\n",
    "    return np.mean(autocrr_lag2_arr), np.std(autocrr_lag2_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQR_function(numadult_matrix):\n",
    "    \"\"\"This function takes numadult_matrix as input and returns the mean and sd of the autocorrelation lag 2\n",
    "\n",
    "    Args: numadult_matrix (array): array of adult population sizes for each generation\n",
    "\n",
    "    Returns:\n",
    "    mean_autocrr_lag2 (float): mean of the autocorrelation lag 2 (over all replicates)\n",
    "    sd_autocrr_lag2 (float): standard deviation of the autocorrelation lag 2 (over all replicates)\"\"\"\n",
    "\n",
    "\n",
    "    #numadult_matrixt = log_diff(numadult_matrix)\n",
    "    if numadult_matrix.ndim == 1:\n",
    "        numadult_matrix = np.expand_dims(numadult_matrix,axis=1)\n",
    "    reps = np.shape(numadult_matrix)[1]\n",
    "    gens = np.shape(numadult_matrix)[0]\n",
    "    iqr_arr = np.zeros(reps) # array of autocorrelation lag 1 for each replicate\n",
    "    for i in range(reps):\n",
    "        s = pd.Series(numadult_matrix[:,i])\n",
    "        iqr_arr[i] = stats.iqr(s)\n",
    "        #autocrr_lag2_arr[i] = np.correlate(numadult_matrix[:,i],numadult_matrix[1:,i],\"full\")[gens + 1]\n",
    "    return np.mean(iqr_arr), np.std(iqr_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(exp_data,sim_data):\n",
    "    \"\"\"This function takes the experimental data \n",
    "    and the simulated data as input \n",
    "    and returns the cost function value\n",
    "    \n",
    "    Args: expt_data,sim_data\n",
    "    \n",
    "    Returns: cost function value = abs((exp_mean_pop_size - sim_mean_pop_size)/exp_mean_pop_size) \n",
    "    + abs((exp_mean_FI - sim_mean_FI)/exp_mean_FI) \n",
    "    + abs((exp_mean_CV - sim_mean_CV)/exp_mean_CV) \n",
    "    + abs((exp_mean_autocrr_lag1 - sim_mean_autocrr_lag1)/exp_mean_autocrr_lag1)\n",
    "    + abs((exp_mean_autocrr_lag2 - sim_mean_autocrr_lag2)/exp_mean_autocrr_lag2)\"\"\"     \n",
    "    exp_mean_pop_size = round(np.mean(exp_data))\n",
    "    exp_mean_FI = FI_numadult_matrix(exp_data)[0]\n",
    "    exp_mean_CV = CV(exp_data)[0]\n",
    "    exp_mean_autocrr_lag1 = autocrr_lag1(exp_data)[0]\n",
    "    exp_mean_autocrr_lag2 = autocrr_lag2(exp_data)[0]\n",
    "\n",
    "    sim_mean_pop_size = round(np.mean(sim_data))\n",
    "    sim_mean_FI = FI_numadult_matrix(sim_data)[0]\n",
    "    sim_mean_CV =  CV(sim_data)[0]\n",
    "    sim_mean_autocrr_lag1 = autocrr_lag1(sim_data)[0]\n",
    "    sim_mean_autocrr_lag2 = autocrr_lag2(sim_data)[0]\n",
    "\n",
    "    cost = abs((exp_mean_pop_size - sim_mean_pop_size)/exp_mean_pop_size) + abs((exp_mean_FI - sim_mean_FI)/exp_mean_FI) + abs((exp_mean_CV - sim_mean_CV)/exp_mean_CV) + abs((exp_mean_autocrr_lag1 - sim_mean_autocrr_lag1)/exp_mean_autocrr_lag1) + abs((exp_mean_autocrr_lag2 - sim_mean_autocrr_lag2)/exp_mean_autocrr_lag2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function_2_norm_simplified(exp_data,sim_data):\n",
    "    \"\"\"This function takes the experimental data \n",
    "    and the simulated data as input \n",
    "    and returns the cost function value\n",
    "    \n",
    "    Args: expt_data,sim_data\n",
    "    \n",
    "    Returns: cost function value = abs((exp_mean_pop_size - sim_mean_pop_size)/exp_mean_pop_size) \n",
    "    + abs((exp_mean_FI - sim_mean_FI)/exp_mean_FI) \n",
    "    + abs((exp_mean_autocrr_lag1 - sim_mean_autocrr_lag1)/exp_mean_autocrr_lag1)\n",
    "    + abs((exp_mean_autocrr_lag2 - sim_mean_autocrr_lag2)/exp_mean_autocrr_lag2)\"\"\"     \n",
    "    exp_mean_pop_size = round(np.mean(exp_data))\n",
    "    exp_mean_FI = FI_numadult_matrix(exp_data)[0]\n",
    "    exp_mean_autocrr_lag2 = autocrr_lag2(exp_data)[0]\n",
    "\n",
    "    sim_mean_pop_size = round(np.mean(sim_data))\n",
    "    sim_mean_FI = FI_numadult_matrix(sim_data)[0]\n",
    " \n",
    "    sim_mean_autocrr_lag2 = autocrr_lag2(sim_data)[0]\n",
    "\n",
    "    cost = np.sqrt(((exp_mean_pop_size - sim_mean_pop_size)/exp_mean_pop_size)**2 + ((exp_mean_FI - sim_mean_FI)/exp_mean_FI)**2 + ((exp_mean_autocrr_lag2 - sim_mean_autocrr_lag2)/exp_mean_autocrr_lag2)**2)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new cost function\n",
    "\n",
    "#at metapopulation level - mean, FI, synchrony,  IQR\n",
    "#both subpops - autocorr 2 (apply right way to match)\n",
    "\n",
    "def cost_function_new(exp_data_meta, exp_data_patch1, exp_data_patch2,sim_data_meta, sim_data_patch1, sim_data_patch2):\n",
    "    \"\"\"This function takes the experimental data \n",
    "    and the simulated data as input \n",
    "    and returns the cost function value\n",
    "    \n",
    "    Args: expt_data,sim_data\n",
    "    \n",
    "    Returns: cost function value = abs((exp_mean_pop_size - sim_mean_pop_size)/exp_mean_pop_size) \n",
    "    + abs((exp_mean_FI - sim_mean_FI)/exp_mean_FI) \n",
    "    + abs((exp_mean_autocrr_lag1 - sim_mean_autocrr_lag1)/exp_mean_autocrr_lag1)\n",
    "    + abs((exp_mean_autocrr_lag2 - sim_mean_autocrr_lag2)/exp_mean_autocrr_lag2)\"\"\"  \n",
    "   \n",
    "   #add synchrony\n",
    "    meta_exp_mean_pop_size = round(np.mean(exp_data_meta))\n",
    "    meta_exp_mean_FI = FI_numadult_matrix(exp_data_meta)[0]\n",
    "    meta_exp_mean_IQR = IQR_function(exp_data_meta)[0]\n",
    "\n",
    "    meta_sim_mean_pop_size = round(np.mean(sim_data_meta))\n",
    "    meta_sim_mean_FI = FI_numadult_matrix(sim_data_meta)[0]\n",
    "    meta_sim_mean_IQR = IQR_function(sim_data_meta)[0]\n",
    " \n",
    "    meta_cost = np.sqrt(((meta_exp_mean_pop_size - meta_sim_mean_pop_size)/meta_exp_mean_pop_size)**2 + ((meta_exp_mean_FI - meta_sim_mean_FI)/meta_exp_mean_FI)**2 + ((meta_exp_mean_IQR - meta_sim_mean_IQR)/meta_exp_mean_IQR)**2)\n",
    "    \n",
    "    patch1_exp_mean_autocorr = autocrr_lag2(exp_data_patch1)[0]\n",
    "    patch2_exp_mean_autocorr = autocrr_lag2(exp_data_patch2)[0]\n",
    "\n",
    "    patch1_sim_mean_autocorr = autocrr_lag2(sim_data_patch1)[0]\n",
    "    patch2_sim_mean_autocorr = autocrr_lag2(sim_data_patch2)[0]\n",
    "\n",
    "    subpop_cost_proper_labels = np.sqrt(((patch1_exp_mean_autocorr - patch1_sim_mean_autocorr)/patch1_exp_mean_autocorr)**2 + ((patch2_exp_mean_autocorr - patch2_sim_mean_autocorr)/patch2_exp_mean_autocorr)**2)   \n",
    "    subpop_cost_switched_labels = np.sqrt(((patch1_exp_mean_autocorr - patch2_sim_mean_autocorr)/patch1_exp_mean_autocorr)**2 + ((patch2_exp_mean_autocorr - patch1_sim_mean_autocorr)/patch2_exp_mean_autocorr)**2)\n",
    "\n",
    "    subpop_cost_considered = np.min([subpop_cost_proper_labels,subpop_cost_switched_labels])\n",
    "\n",
    "    total_cost = meta_cost + subpop_cost_considered\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_validation(exp_data,sim_data):\n",
    "\n",
    "    \"\"\"This function makes the plots of characteristics \n",
    "    for testing/validation\n",
    "    \n",
    "    args: experimental data, simulation data\n",
    "    \n",
    "    returns: plots of population size, FI, CV, lag 1 and lag 2 \n",
    "    autocorrelation for\n",
    "    experimental data and simulation data side by side\n",
    "    \"\"\"\n",
    " \n",
    "    #boxplot of the population sizes\n",
    "    all_points_list = [exp_data.flatten(),sim_data.flatten()]\n",
    "    plt.boxplot(all_points_list,meanline=True,showmeans=True)\n",
    "    plt.ylim(0, 350)\n",
    "    plt.xticks([1, 2], ['exp', 'sim'])\n",
    "    plt.ylabel('Population size')\n",
    "    myHandle = [Line2D([], [], color='orange', lw = 3), Line2D([], [], color='green', linestyle = \"dashed\", lw = 3)]\n",
    "    plt.legend(handles = myHandle, labels=['median', 'mean'], frameon = True, loc = 'best', fontsize = 12)\n",
    "    plt.show()\n",
    "\n",
    "    ###barplot of fluctuation index\n",
    "    exp_FI_mean, exp_FI_sd = FI_numadult_matrix(exp_data)\n",
    "    sim_FI_mean, sim_FI_sd = FI_numadult_matrix(sim_data)\n",
    "\n",
    "    # Create lists for the plot\n",
    "    tags = ['exp', 'sim']\n",
    "    x_pos = np.arange(len(tags))\n",
    "    mean_FI = [exp_FI_mean, sim_FI_mean]\n",
    "    error_FI = [exp_FI_sd, sim_FI_sd]\n",
    "    # Build the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, mean_FI, yerr=error_FI, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Fluctuation Index (FI)')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(tags)    \n",
    "    #ax.set_title('Coefficent of Thermal Expansion (CTE) of Three Metals')\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.yticks(np.arange(0, 2.5, 0.5))\n",
    "    plt.show()\n",
    "\n",
    "    # barplt of CV\n",
    "\n",
    "    exp_CV_mean, exp_CV_sd = CV(exp_data)\n",
    "    sim_CV_mean, sim_CV_sd = CV(sim_data)\n",
    "\n",
    "    # Create lists for the plot\n",
    "    tags = ['exp', 'sim']\n",
    "    x_pos = np.arange(len(tags))\n",
    "    mean_CV = [exp_CV_mean, sim_CV_mean]\n",
    "    error_CV = [exp_CV_sd, sim_CV_sd]\n",
    "    # Build the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, mean_CV, yerr=error_CV, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Coefficient of Variation (CV)')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(tags)\n",
    "    #ax.set_title('Coefficent of Thermal Expansion (CTE) of Three Metals')\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.yticks(np.arange(0, 2.5, 0.5))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # barplot of lag 1 autocorrelation\n",
    "\n",
    "    exp_ac1_mean, exp_ac1_sd = autocrr_lag1(exp_data)\n",
    "    sim_ac1_mean, sim_ac1_sd = autocrr_lag1(sim_data)\n",
    "\n",
    "    # Create lists for the plot\n",
    "    tags = ['exp', 'sim']\n",
    "    x_pos = np.arange(len(tags))\n",
    "    mean_ac1 = [exp_ac1_mean,sim_ac1_mean]\n",
    "    error_ac1 = [exp_ac1_sd , sim_ac1_sd]\n",
    "    # Build the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, mean_ac1, yerr=error_ac1, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Lag 1 Autocorrelation')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(tags)\n",
    "    #ax.set_title('Coefficent of Thermal Expansion (CTE) of Three Metals')\n",
    "    ax.yaxis.grid(True)\n",
    "    #plt.yticks(np.arange(0, 2.5, 0.5))\n",
    "    plt.show()\n",
    "\n",
    "    # barplot of lag 2 autocorrelation\n",
    "    exp_ac2_mean, exp_ac2_sd = autocrr_lag2(exp_data)\n",
    "    sim_ac2_mean, sim_ac2_sd = autocrr_lag2(sim_data)\n",
    "\n",
    "    # Create lists for the plot\n",
    "    tags = ['exp', 'sim']\n",
    "    x_pos = np.arange(len(tags))\n",
    "    mean_ac2 = [exp_ac2_mean,sim_ac2_mean]\n",
    "    error_ac2 = [exp_ac2_sd , sim_ac2_sd]\n",
    "    # Build the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, mean_ac2, yerr=error_ac2, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Lag 2 Autocorrelation')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(tags)\n",
    "    #ax.set_title('Coefficent of Thermal Expansion (CTE) of Three Metals')\n",
    "    ax.yaxis.grid(True)\n",
    "    #plt.yticks(np.arange(0, 2.5, 0.5))\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_charateristics(data_list,labels_list):\n",
    "\n",
    "    \"\"\"This function makes the plots of characteristics \n",
    "    for the given data\n",
    "    \n",
    "    args: \n",
    "    data_list - list of data to be plotted (eg. [numadult_matrix1,numadult_matrix2,metapop_nadult_matrix] ) \n",
    "    labels_list - list of labels for the data (eg. ['patch 1','patch 2','metapopulation'] )\n",
    "    \n",
    "    returns: \n",
    "    plots of population size, FI, CV, lag 1 and lag 2 \n",
    "    autocorrelation for\n",
    "    the given data side by side\n",
    "    \"\"\"\n",
    " \n",
    "    #boxplot of the population sizes\n",
    "    all_points_list = []\n",
    "    for i in range(len(data_list)):\n",
    "        all_points_list.append(data_list[i].flatten())\n",
    "    #all_points_list = [exp_data.flatten(),sim_data.flatten()]\n",
    "    plt.boxplot(all_points_list,meanline=True,showmeans=True)\n",
    "    #plt.ylim(0, 350)\n",
    "    #plt.xticks([1, 2], ['exp', 'sim'])\n",
    "    plt.xticks(np.arange(1,len(labels_list)+1),labels_list)\n",
    "    plt.ylabel('Population size')\n",
    "    myHandle = [Line2D([], [], color='orange', lw = 3), Line2D([], [], color='green', linestyle = \"dashed\", lw = 3)]\n",
    "    plt.legend(handles = myHandle, labels=['median', 'mean'], frameon = True, loc = 'best', fontsize = 12)\n",
    "    plt.show()\n",
    "\n",
    "    ###barplot of fluctuation index\n",
    "    #exp_FI_mean, exp_FI_sd = FI_numadult_matrix(exp_data)\n",
    "    #im_FI_mean, sim_FI_sd = FI_numadult_matrix(sim_data)\n",
    "    mean_FI = []\n",
    "    error_FI = []\n",
    "    for i in range(len(data_list)):\n",
    "        mean_FI.append(FI_numadult_matrix(data_list[i])[0])\n",
    "        error_FI.append(FI_numadult_matrix(data_list[i])[1])\n",
    "\n",
    "    # Create lists for the plot\n",
    "    x_pos = np.arange(len(labels_list))\n",
    "    #mean_FI = [exp_FI_mean, sim_FI_mean]\n",
    "    #error_FI = [exp_FI_sd, sim_FI_sd]\n",
    "    # Build the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, mean_FI, yerr=error_FI, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Fluctuation Index (FI)')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels_list)    \n",
    "    #ax.set_title('Coefficent of Thermal Expansion (CTE) of Three Metals')\n",
    "    ax.yaxis.grid(True)\n",
    "    #plt.yticks(np.arange(0, 2.5, 0.5))\n",
    "    plt.show()\n",
    "\n",
    "    # barplt of CV\n",
    "    mean_CV = []\n",
    "    error_CV = []\n",
    "    for i in range(len(data_list)):\n",
    "        mean_CV.append(CV(data_list[i])[0])\n",
    "        error_CV.append(CV(data_list[i])[1])\n",
    "\n",
    "    # Create lists for the plot\n",
    "    #tags = ['exp', 'sim']\n",
    "    x_pos = np.arange(len(labels_list))\n",
    "    #mean_CV = [exp_CV_mean, sim_CV_mean]\n",
    "    #error_CV = [exp_CV_sd, sim_CV_sd]\n",
    "    # Build the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, mean_CV, yerr=error_CV, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Coefficient of Variation (CV)')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels_list)\n",
    "    #ax.set_title('Coefficent of Thermal Expansion (CTE) of Three Metals')\n",
    "    ax.yaxis.grid(True)\n",
    "    #plt.yticks(np.arange(0, 2.5, 0.5))\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # barplot of lag 1 autocorrelation\n",
    "    mean_ac1 = []\n",
    "    error_ac1 = []\n",
    "    for i in range(len(data_list)):\n",
    "        mean_ac1.append(autocrr_lag1(data_list[i])[0])\n",
    "        error_ac1.append(autocrr_lag1(data_list[i])[1])\n",
    "\n",
    "    # Create lists for the plot\n",
    "    #tags = ['exp', 'sim']\n",
    "    x_pos = np.arange(len(labels_list))\n",
    "    #mean_ac1 = [exp_ac1_mean,sim_ac1_mean]\n",
    "    #rror_ac1 = [exp_ac1_sd , sim_ac1_sd]\n",
    "    # Build the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, mean_ac1, yerr=error_ac1, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Lag 1 Autocorrelation')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels_list)\n",
    "    #ax.set_title('Coefficent of Thermal Expansion (CTE) of Three Metals')\n",
    "    ax.yaxis.grid(True)\n",
    "    #plt.yticks(np.arange(0, 2.5, 0.5))\n",
    "    plt.show()\n",
    "\n",
    "    # barplot of lag 2 autocorrelation\n",
    "    mean_ac2 = []\n",
    "    error_ac2 = []\n",
    "    for i in range(len(data_list)):\n",
    "        mean_ac2.append(autocrr_lag2(data_list[i])[0])\n",
    "        error_ac2.append(autocrr_lag2(data_list[i])[1])\n",
    "\n",
    "    # Create lists for the plot\n",
    "    #tags = ['exp', 'sim']\n",
    "    x_pos = np.arange(len(labels_list))\n",
    "    #mean_ac2 = [exp_ac2_mean,sim_ac2_mean]\n",
    "    #error_ac2 = [exp_ac2_sd , sim_ac2_sd]\n",
    "    # Build the plot\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, mean_ac2, yerr=error_ac2, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Lag 2 Autocorrelation')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels_list)\n",
    "    #ax.set_title('Coefficent of Thermal Expansion (CTE) of Three Metals')\n",
    "    ax.yaxis.grid(True)\n",
    "    #plt.yticks(np.arange(0, 2.5, 0.5))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimental Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_15_data = pd.read_excel(\"LHLH_data.xls\",sheet_name=\"15_percent_migration\") #scanning the file and taking the relavant sheet\n",
    "migration_15_nadult_matrix1, migration_15_nadult_matrix2, migration_15_metapop_nadult_matrix, migration_15_extinctions_matrix1, migration_15_extinctions_matrix2, migration_15_metapop_extinctions_matrix = patch_data(migration_15_data)\n",
    "migration_15_metapop_nadult_matrix = Metapop_numadult_matrix(migration_15_nadult_matrix1,migration_15_nadult_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "migration_45_data = pd.read_excel(\"LHLH_data.xls\",sheet_name=\"45_percent_migration\")\n",
    "migration_45_nadult_matrix1, migration_45_nadult_matrix2, migration_45_metapop_nadult_matrix, migration_45_extinctions_matrix1, migration_45_extinctions_matrix2, migration_45_metapop_extinctions_matrix = patch_data(migration_45_data)\n",
    "migration_45_metapop_nadult_matrix = Metapop_numadult_matrix(migration_45_nadult_matrix1,migration_45_nadult_matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different characterstics sub, meta pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''First only metapopulation characterstics.\n",
    " Only the basic charactrstics which were already used in the previous paper.\n",
    "   First only 45%'''\n",
    "\n",
    "def generate_characteristics_dataframe_for_given_timeseries_matrix(timeseries_matrix):\n",
    "    number_of_time_series = timeseries_matrix.shape[1]\n",
    "    \n",
    "    number_of_characteristics = 5\n",
    "    characteristics_array = np.zeros((number_of_time_series, number_of_characteristics))\n",
    "\n",
    "    #just the basic characteristics\n",
    "    for i in range(number_of_time_series):\n",
    "        characteristics_array[i, 0] = np.mean(timeseries_matrix[:,i])\n",
    "        characteristics_array[i, 1] = CV(timeseries_matrix[:,i])[0]\n",
    "        characteristics_array[i, 2] = FI_numadult_matrix(timeseries_matrix[:,i])[0]\n",
    "        characteristics_array[i, 3] = autocrr_lag1(timeseries_matrix[:,i])[0]\n",
    "        characteristics_array[i, 4] = autocrr_lag2(timeseries_matrix[:,i])[0]\n",
    "    \n",
    "    column_names =['mean', 'CV', 'FI', 'autocorr_lag1', 'autocorr_lag2']\n",
    "\n",
    "    characteristics_dataframe = pd.DataFrame(characteristics_array, columns=column_names) \n",
    "\n",
    "    return characteristics_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concantenating all population matrices\n",
    "\n",
    "subpop_45_both_concatenated = np.concatenate((migration_45_nadult_matrix1, migration_45_nadult_matrix2), axis=1)\n",
    "subpop_15_both_concatenated = np.concatenate((migration_15_nadult_matrix1, migration_15_nadult_matrix2), axis=1)\n",
    "\n",
    "metapop_with_subpop_45_concatenated = np.concatenate((migration_45_metapop_nadult_matrix, subpop_45_both_concatenated), axis=1)\n",
    "metapop_with_subpop_15_concatenated = np.concatenate((migration_15_metapop_nadult_matrix, subpop_15_both_concatenated), axis=1)\n",
    "\n",
    "all_metapop_concatenated = np.concatenate((metapop_with_subpop_45_concatenated, metapop_with_subpop_15_concatenated), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   mean        CV        FI  autocorr_lag1  autocorr_lag2\n",
      "mean           1.000000 -0.434584 -0.352345       0.070604      -0.197746\n",
      "CV            -0.434584  1.000000  0.929393      -0.587081       0.074803\n",
      "FI            -0.352345  0.929393  1.000000      -0.815947       0.124440\n",
      "autocorr_lag1  0.070604 -0.587081 -0.815947       1.000000      -0.178953\n",
      "autocorr_lag2 -0.197746  0.074803  0.124440      -0.178953       1.000000\n"
     ]
    }
   ],
   "source": [
    "all_metapop_characteristics = generate_characteristics_dataframe_for_given_timeseries_matrix(all_metapop_concatenated)\n",
    "print(all_metapop_characteristics.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0389699965513277\n",
      "0.04514916227374008\n",
      "0.3869947799614197\n",
      "0.026018654884634288\n",
      "0.05216883957675545\n",
      "0.13941935092941657\n"
     ]
    }
   ],
   "source": [
    "#checking if subpops are symmetric\n",
    "\n",
    "#patch 1 45 characterstics\n",
    "subpop_means_list_45_patch1 = []\n",
    "subpop_FIs_list_45_patch1 = []\n",
    "subpop_autocorr2_list_45_patch1 = []\n",
    "\n",
    "#patch 2 45 chracterstics\n",
    "subpop_means_list_45_patch2 = []\n",
    "subpop_FIs_list_45_patch2 = []\n",
    "subpop_autocorr2_list_45_patch2 = []\n",
    "\n",
    "#patch 1 15 char.\n",
    "\n",
    "subpop_means_list_15_patch1= []\n",
    "subpop_FIs_list_15_patch1 = []\n",
    "subpop_autocorr2_list_15_patch1 = []\n",
    "\n",
    "#patch 2 15 char.\n",
    "\n",
    "subpop_means_list_15_patch2 = []\n",
    "subpop_FIs_list_15_patch2 = []\n",
    "subpop_autocorr2_list_15_patch2 = []\n",
    "\n",
    "\n",
    "#45 migration\n",
    "for k in range(4):\n",
    "    subpop_means_list_45_patch1.append(np.mean(migration_45_nadult_matrix1[:,k]))\n",
    "    subpop_FIs_list_45_patch1.append(FI_numadult_matrix(migration_45_nadult_matrix1[:,k])[0])\n",
    "    subpop_autocorr2_list_45_patch1.append(autocrr_lag2(migration_45_nadult_matrix1[:,k])[0])\n",
    "\n",
    "    subpop_means_list_45_patch2.append(np.mean(migration_45_nadult_matrix2[:,k]))\n",
    "    subpop_FIs_list_45_patch2.append(FI_numadult_matrix(migration_45_nadult_matrix2[:,k])[0])\n",
    "    subpop_autocorr2_list_45_patch2.append(autocrr_lag2(migration_45_nadult_matrix2[:,k])[0])\n",
    "\n",
    "\n",
    "    subpop_means_list_15_patch1.append(np.mean(migration_15_nadult_matrix1[:,k]))\n",
    "    subpop_FIs_list_15_patch1.append(FI_numadult_matrix(migration_15_nadult_matrix1[:,k])[0])\n",
    "    subpop_autocorr2_list_15_patch1.append(autocrr_lag2(migration_15_nadult_matrix1[:,k])[0])\n",
    "\n",
    "    subpop_means_list_15_patch2.append(np.mean(migration_15_nadult_matrix2[:,k]))\n",
    "    subpop_FIs_list_15_patch2.append(FI_numadult_matrix(migration_15_nadult_matrix2[:,k])[0])\n",
    "    subpop_autocorr2_list_15_patch2.append(autocrr_lag2(migration_15_nadult_matrix2[:,k])[0])\n",
    "\n",
    "#let me just play with 45 for now. Here, I will take difference, absolute value then average. Normalise by dividing wth avg patch 1 and patch 2\n",
    "#First for mean. Then repeat with other quanitities\n",
    "\n",
    "normalised_mean_diff_bw_patches_45 = (np.mean(np.abs(np.array(subpop_means_list_45_patch1) - np.array(subpop_means_list_45_patch2))))/(np.mean(np.array(subpop_means_list_45_patch1) + np.array(subpop_means_list_45_patch2)))\n",
    "normalised_FI_diff_bw_patches_45 = (np.mean(np.abs(np.array(subpop_FIs_list_45_patch1) - np.array(subpop_FIs_list_45_patch2))))/(np.mean(np.array(subpop_FIs_list_45_patch1) + np.array(subpop_FIs_list_45_patch2)))\n",
    "normalised_autocorr2_diff_bw_patches_45 = (np.mean(np.abs(np.array(subpop_autocorr2_list_45_patch1) - np.array(subpop_autocorr2_list_45_patch2))))/(np.mean(np.array(subpop_autocorr2_list_45_patch1) + np.array(subpop_autocorr2_list_45_patch2)))\n",
    "\n",
    "print(normalised_mean_diff_bw_patches_45)\n",
    "print(normalised_FI_diff_bw_patches_45)\n",
    "print(normalised_autocorr2_diff_bw_patches_45)\n",
    "\n",
    "#conclusion \n",
    "\n",
    "#mean and FI between two patches rougj;u the same, less than 4% diff. Autocorr2 is 38% diff.\n",
    "'''\n",
    "\n",
    "both_15_and_45_patch_1_means = np.array([subpop_means_list_45_patch1, subpop_means_list_15_patch1])\n",
    "avg_15_and_45_patch_1_means = np.mean(both_15_and_45_patch_1_means)\n",
    "\n",
    "both_15_and_45_patch_2_means = np.array([subpop_means_list_45_patch2, subpop_means_list_15_patch2])\n",
    "avg_15_and_45_patch_2_means = np.mean(both_15_and_45_patch_2_means)\n",
    "\n",
    "both_15_and_45_patch_1_means - \n",
    "\n",
    "both_15_and_45_patch_1_FIs = np.array([subpop_FIs_list_45_patch1, subpop_FIs_list_15_patch1])\n",
    "both_15_and_45_patch_2_FIs = np.array([subpop_FIs_list_45_patch2, subpop_FIs_list_15_patch2])\n",
    "\n",
    "both_15_and_45_patch_1_autocorr2 = np.array([subpop_autocorr2_list_45_patch1, subpop_autocorr2_list_15_patch1])\n",
    "both_15_and_45_patch_2_autocorr2 = np.array([subpop_autocorr2_list_45_patch2, subpop_autocorr2_list_15_patch2])\n",
    "\n",
    "'''\n",
    "#average of patch 1 and patch 2\n",
    "\n",
    "normalised_mean_diff_bw_patches_15 = (np.mean(np.abs(np.array(subpop_means_list_15_patch1) - np.array(subpop_means_list_15_patch2))))/(np.mean(np.array(subpop_means_list_15_patch1) + np.array(subpop_means_list_15_patch2)))\n",
    "normalised_FI_diff_bw_patches_15 = (np.mean(np.abs(np.array(subpop_FIs_list_15_patch1) - np.array(subpop_FIs_list_15_patch2))))/(np.mean(np.array(subpop_FIs_list_15_patch1) + np.array(subpop_FIs_list_15_patch2)))\n",
    "normalised_autocorr2_diff_bw_patches_15 = (np.mean(np.abs(np.array(subpop_autocorr2_list_15_patch1) - np.array(subpop_autocorr2_list_15_patch2))))/(np.mean(np.array(subpop_autocorr2_list_15_patch1) + np.array(subpop_autocorr2_list_15_patch2)))\n",
    "\n",
    "print(normalised_mean_diff_bw_patches_15)\n",
    "print(normalised_FI_diff_bw_patches_15)\n",
    "print(normalised_autocorr2_diff_bw_patches_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17\n",
      "0.09814186895109354\n",
      "----autocorr2---\n",
      "0.08967115572347063 patch1\n",
      "0.25490904859274893 patch2\n",
      "0.17229010215810978 avg of patch1 and patch2\n",
      "0.3188803893460498 meta\n"
     ]
    }
   ],
   "source": [
    "#checking if even in sims patch 1 and patch 2 have similar fluctiation indices\n",
    "\n",
    "\n",
    "food = 2\n",
    "sen_adden = 0.17\n",
    "sen_adsize = 1.7\n",
    "adnut = 1.49\n",
    "generations = 26\n",
    "replicates = 25\n",
    "f = 0.15\n",
    "numegg = 18\n",
    "LHLH_numadult_matrix1,LHLH_numegg_matrix1,LHLH_extinctions_matrix1,LHLH_numadult_matrix2,LHLH_numegg_matrix2,LHLH_extinctions_matrix2 = Metapop_Simulation(numegg,food,adnut,numegg,food,adnut,generations,replicates)\n",
    "LHLH_metapop_nadult_matrix = Metapop_numadult_matrix(LHLH_numadult_matrix1,LHLH_numadult_matrix2)\n",
    "\n",
    "#First seeing if patch1, and patch2 re similar\n",
    "\n",
    "patch_1_FI_values = []\n",
    "patch_2_FI_value = []\n",
    "for i in range(4):\n",
    "    patch_1_FI_values.append(FI_numadult_matrix(LHLH_numadult_matrix1[:,i])[0])\n",
    "    patch_2_FI_value.append(FI_numadult_matrix(LHLH_numadult_matrix2[:,i])[0])\n",
    "\n",
    "\n",
    "normalised_FI_diff_bw_patches_sims = (np.mean(np.abs(np.array(patch_1_FI_values) - np.array(patch_2_FI_value))))/(np.mean(np.array(patch_1_FI_values) + np.array(patch_2_FI_value)))\n",
    "print(normalised_FI_diff_bw_patches_sims)\n",
    "\n",
    "print(\"----autocorr2---\")\n",
    "#Autocorr2 relations patch1, patch2 and meta sims \n",
    "patch_1_autocorr2_values = []\n",
    "patch_2_autocorr2_value = []\n",
    "meta_autocorr2_value = []\n",
    "\n",
    "for i in range(4):\n",
    "    patch_1_autocorr2_values.append(autocrr_lag2(LHLH_numadult_matrix1[:,i])[0])\n",
    "    patch_2_autocorr2_value.append(autocrr_lag2(LHLH_numadult_matrix2[:,i])[0])\n",
    "    meta_autocorr2_value.append(autocrr_lag2(LHLH_metapop_nadult_matrix[:,i])[0])\n",
    "\n",
    "print(np.mean(patch_1_autocorr2_values), \"patch1\")\n",
    "print(np.mean(patch_2_autocorr2_value), \"patch2\")\n",
    "\n",
    "print((np.mean(patch_1_autocorr2_values) + np.mean(patch_2_autocorr2_value))/2, \"avg of patch1 and patch2\")\n",
    "print(np.mean(meta_autocorr2_value), \"meta\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#investigate how Fi and autocorr 2. of sub and meta relate to each other (sims and data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined     FI_meta  FI_patch1\n",
      "0  1.516580   1.660144\n",
      "1  1.035343   1.097561\n",
      "2  1.332043   1.412434\n",
      "3  1.277633   1.243697\n",
      "4  0.991176   1.276650\n",
      "5  0.547928   1.079327\n",
      "6  1.465327   1.571737\n",
      "7  1.100879   1.528864\n",
      "            FI_meta  FI_patch1\n",
      "FI_meta    1.000000   0.784339\n",
      "FI_patch1  0.784339   1.000000\n",
      "45     FI_meta  FI_patch1\n",
      "0  1.516580   1.660144\n",
      "1  1.035343   1.097561\n",
      "2  1.332043   1.412434\n",
      "3  1.277633   1.243697\n",
      "            FI_meta  FI_patch1\n",
      "FI_meta    1.000000   0.963127\n",
      "FI_patch1  0.963127   1.000000\n",
      "15     FI_meta  FI_patch1\n",
      "0  0.991176   1.276650\n",
      "1  0.547928   1.079327\n",
      "2  1.465327   1.571737\n",
      "3  1.100879   1.528864\n",
      "            FI_meta  FI_patch1\n",
      "FI_meta    1.000000   0.930106\n",
      "FI_patch1  0.930106   1.000000\n"
     ]
    }
   ],
   "source": [
    "#how FI of patch 1 is correlated with FI of meta. First with exp then with sim. \n",
    "\n",
    "FI_meta_and_patch1_matrix_45 = np.zeros((4,2))\n",
    "\n",
    "for i in range(4):  \n",
    "    FI_meta_and_patch1_matrix_45[i,0] = FI_numadult_matrix(migration_45_metapop_nadult_matrix[:,i])[0]\n",
    "    FI_meta_and_patch1_matrix_45[i,1] = FI_numadult_matrix(migration_45_nadult_matrix1[:,i])[0] \n",
    "\n",
    "FI_meta_and_patch1_matrix_15 = np.zeros((4,2))\n",
    "\n",
    "for i in range(4):\n",
    "    FI_meta_and_patch1_matrix_15[i,0] = FI_numadult_matrix(migration_15_metapop_nadult_matrix[:,i])[0]\n",
    "    FI_meta_and_patch1_matrix_15[i,1] = FI_numadult_matrix(migration_15_nadult_matrix1[:,i])[0]\n",
    "\n",
    "combied_FI_meta_and_patch1 = np.concatenate((FI_meta_and_patch1_matrix_45, FI_meta_and_patch1_matrix_15), axis=0)\n",
    "\n",
    "col_names = ['FI_meta', 'FI_patch1']\n",
    "combied_FI_meta_and_patch1_dataframe = pd.DataFrame(combied_FI_meta_and_patch1, columns=col_names)\n",
    "\n",
    "print(\"combined\",combied_FI_meta_and_patch1_dataframe)\n",
    "print(combied_FI_meta_and_patch1_dataframe.corr())\n",
    "\n",
    "FI_meta_and_patch1_45_dataframe = pd.DataFrame(FI_meta_and_patch1_matrix_45, columns=col_names)\n",
    "\n",
    "print(\"45\", FI_meta_and_patch1_45_dataframe)\n",
    "print(FI_meta_and_patch1_45_dataframe.corr())\n",
    "\n",
    "FI_meta_and_patch1_15_dataframe = pd.DataFrame(FI_meta_and_patch1_matrix_15, columns=col_names)\n",
    "\n",
    "print(\"15\",FI_meta_and_patch1_15_dataframe)\n",
    "print(FI_meta_and_patch1_15_dataframe.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   autocorr_meta  autocorr_patch1  autocorr_patch2  patch1,patch2 avg\n",
      "0       0.078648         0.118249         0.001952           0.060101\n",
      "1       0.185132         0.198684         0.181715           0.190200\n",
      "2       0.203674         0.303129         0.062567           0.182848\n",
      "3       0.391477         0.231449         0.460751           0.346100\n",
      "                   autocorr_meta  autocorr_patch1  autocorr_patch2  \\\n",
      "autocorr_meta           1.000000         0.520659         0.945581   \n",
      "autocorr_patch1         0.520659         1.000000         0.244282   \n",
      "autocorr_patch2         0.945581         0.244282         1.000000   \n",
      "patch1,patch2 avg       0.991502         0.539358         0.948321   \n",
      "\n",
      "                   patch1,patch2 avg  \n",
      "autocorr_meta               0.991502  \n",
      "autocorr_patch1             0.539358  \n",
      "autocorr_patch2             0.948321  \n",
      "patch1,patch2 avg           1.000000  \n",
      "---15----\n",
      "   autocorr_meta  autocorr_patch1  autocorr_patch2  patch1,patch2 avg\n",
      "0      -0.066580        -0.006033         0.114036           0.054001\n",
      "1       0.280923         0.431647         0.570137           0.500892\n",
      "2       0.460063         0.407255         0.386176           0.396716\n",
      "3       0.232679         0.323918         0.257193           0.290555\n",
      "                   autocorr_meta  autocorr_patch1  autocorr_patch2  \\\n",
      "autocorr_meta           1.000000         0.920481         0.700079   \n",
      "autocorr_patch1         0.920481         1.000000         0.868175   \n",
      "autocorr_patch2         0.700079         0.868175         1.000000   \n",
      "patch1,patch2 avg       0.840755         0.967894         0.965040   \n",
      "\n",
      "                   patch1,patch2 avg  \n",
      "autocorr_meta               0.840755  \n",
      "autocorr_patch1             0.967894  \n",
      "autocorr_patch2             0.965040  \n",
      "patch1,patch2 avg           1.000000  \n"
     ]
    }
   ],
   "source": [
    "#see how autocorr values relate to one another\n",
    "\n",
    "autocorr2_meta_patch1_patch_2_matrix_45 = np.zeros((4,4))\n",
    "\n",
    "for i in range(4):\n",
    "    autocorr2_meta_patch1_patch_2_matrix_45[i,0] = autocrr_lag2(migration_45_metapop_nadult_matrix[:,i])[0]\n",
    "    autocorr2_meta_patch1_patch_2_matrix_45[i,1] = autocrr_lag2(migration_45_nadult_matrix1[:,i])[0]\n",
    "    autocorr2_meta_patch1_patch_2_matrix_45[i,2] = autocrr_lag2(migration_45_nadult_matrix2[:,i])[0]\n",
    "    autocorr2_meta_patch1_patch_2_matrix_45[i,3] = (autocrr_lag2(migration_45_nadult_matrix1[:,i])[0] + autocrr_lag2(migration_45_nadult_matrix2[:,i])[0])/2\n",
    "\n",
    "col_names = ['autocorr_meta', 'autocorr_patch1', 'autocorr_patch2', \"patch1,patch2 avg\"]\n",
    "autocorr_meta_patch1_patch_2_dataframe_45 = pd.DataFrame(autocorr2_meta_patch1_patch_2_matrix_45, columns=col_names)\n",
    "\n",
    "print(autocorr_meta_patch1_patch_2_dataframe_45)\n",
    "print(autocorr_meta_patch1_patch_2_dataframe_45.corr())\n",
    "\n",
    "\n",
    "print(\"---15----\")\n",
    "\n",
    "\n",
    "autocorr2_meta_patch1_patch_2_matrix_15 = np.zeros((4,4))\n",
    "\n",
    "for i in range(4):\n",
    "    autocorr2_meta_patch1_patch_2_matrix_15[i,0] = autocrr_lag2(migration_15_metapop_nadult_matrix[:,i])[0]\n",
    "    autocorr2_meta_patch1_patch_2_matrix_15[i,1] = autocrr_lag2(migration_15_nadult_matrix1[:,i])[0]\n",
    "    autocorr2_meta_patch1_patch_2_matrix_15[i,2] = autocrr_lag2(migration_15_nadult_matrix2[:,i])[0]\n",
    "    autocorr2_meta_patch1_patch_2_matrix_15[i,3] = (autocrr_lag2(migration_15_nadult_matrix1[:,i])[0] + autocrr_lag2(migration_15_nadult_matrix2[:,i])[0])/2\n",
    "\n",
    "col_names = ['autocorr_meta', 'autocorr_patch1', 'autocorr_patch2', \"patch1,patch2 avg\"]\n",
    "autocorr_meta_patch1_patch_2_dataframe_15 = pd.DataFrame(autocorr2_meta_patch1_patch_2_matrix_15, columns=col_names)\n",
    "\n",
    "print(autocorr_meta_patch1_patch_2_dataframe_15)\n",
    "print(autocorr_meta_patch1_patch_2_dataframe_15.corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08715940952863147\n",
      "0.9676001358064448\n"
     ]
    }
   ],
   "source": [
    "#try calculating synhcrony of patch 1 and patch 2 in sims and exp\n",
    "\n",
    "#first exp\n",
    "\n",
    "print(Pearson_corr_patches(log_diff(migration_45_nadult_matrix1),log_diff(migration_45_nadult_matrix2)))\n",
    "\n",
    "\n",
    "test1 = np.transpose(np.array([ [2, 3, 2, 4]]))\n",
    "test2 = np.transpose(np.array( [2, 4, 2, 4]))\n",
    "\n",
    "\n",
    "\n",
    "print(Pearson_corr_patches(log_diff(test1),log_diff(test2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 67.0625  62.5    124.1875]\n",
      "[59.125  69.9375 93.6875]\n",
      "[[array([ 67.0625,  62.5   , 124.1875])], [array([59.125 , 69.9375, 93.6875])]]\n"
     ]
    }
   ],
   "source": [
    "#finding IQR\n",
    "iqr_45_patch1 = [stats.iqr(migration_45_nadult_matrix1[:,x]) for x in range(4)]\n",
    "iqr_45_patch2 = [stats.iqr(migration_45_nadult_matrix2[:,x]) for x in range(4)]\n",
    "iqr_45_meta = [stats.iqr(migration_45_metapop_nadult_matrix[:,x]) for x in range(4)]\n",
    "\n",
    "iqr_15_patch1 = [stats.iqr(migration_15_nadult_matrix1[:,x]) for x in range(4)]\n",
    "iqr_15_patch2 = [stats.iqr(migration_15_nadult_matrix2[:,x]) for x in range(4)]\n",
    "iqr_15_meta = [stats.iqr(migration_15_metapop_nadult_matrix[:,x]) for x in range(4)]\n",
    "\n",
    "iqr_45_iqr_array = np.array([np.mean(iqr_45_patch1),np.mean(iqr_45_patch2), np.mean(iqr_45_meta)])\n",
    "iqr_15_iqr_array = np.array([np.mean(iqr_15_patch1), np.mean(iqr_15_patch2), np.mean(iqr_15_meta)])\n",
    "\n",
    "print(iqr_45_iqr_array)\n",
    "print(iqr_15_iqr_array)\n",
    "iqr_both = [[iqr_45_iqr_array], [iqr_15_iqr_array]]\n",
    "print(iqr_both)\n",
    "col_names = ['patch1', 'patch2', 'meta']\n",
    "# iqr_dataframe = pd.DataFrame(iqr_both, columns=col_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Particle Swarm Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 14:06:39,001 - pyswarms.single.global_best - INFO - Optimize for 100 iters with {'c1': 1.5, 'c2': 1.5, 'w': 0.7}\n",
      "pyswarms.single.global_best:   0%|          |0/100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy\\lib\\function_base.py:2855: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "pyswarms.single.global_best:   0%|          |0/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m ps\u001b[38;5;241m.\u001b[39msingle\u001b[38;5;241m.\u001b[39mGlobalBestPSO(n_particles\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, dimensions\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, options \u001b[38;5;241m=\u001b[39m options, bounds\u001b[38;5;241m=\u001b[39m bound_values)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Perform optimization\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m best_cost, best_pos \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyswarms\\single\\global_best.py:209\u001b[0m, in \u001b[0;36mGlobalBestPSO.optimize\u001b[1;34m(self, objective_func, iters, n_processes, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m ftol_history \u001b[38;5;241m=\u001b[39m deque(maxlen\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mftol_iter)\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrep\u001b[38;5;241m.\u001b[39mpbar(iters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname) \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(iters):\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;66;03m# Compute cost for current position and personal best\u001b[39;00m\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[1;32m--> 209\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswarm\u001b[38;5;241m.\u001b[39mcurrent_cost \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_objective_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mswarm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobjective_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswarm\u001b[38;5;241m.\u001b[39mpbest_pos, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswarm\u001b[38;5;241m.\u001b[39mpbest_cost \u001b[38;5;241m=\u001b[39m compute_pbest(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswarm)\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# Set best_cost_yet_found for ftol\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pyswarms\\backend\\operators.py:239\u001b[0m, in \u001b[0;36mcompute_objective_function\u001b[1;34m(swarm, objective_func, pool, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Evaluate particles using the objective function\u001b[39;00m\n\u001b[0;32m    215\u001b[0m \n\u001b[0;32m    216\u001b[0m \u001b[38;5;124;03mThis method evaluates each particle in the swarm according to the objective\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    Cost-matrix for the given swarm\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobjective_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mswarm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     results \u001b[38;5;241m=\u001b[39m pool\u001b[38;5;241m.\u001b[39mmap(\n\u001b[0;32m    242\u001b[0m         partial(objective_func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m    243\u001b[0m         np\u001b[38;5;241m.\u001b[39marray_split(swarm\u001b[38;5;241m.\u001b[39mposition, pool\u001b[38;5;241m.\u001b[39m_processes),\n\u001b[0;32m    244\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[46], line 14\u001b[0m, in \u001b[0;36mobjective_function\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     12\u001b[0m sen_adsize \u001b[38;5;241m=\u001b[39m k[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m     13\u001b[0m adnut \u001b[38;5;241m=\u001b[39m k[\u001b[38;5;241m3\u001b[39m]\n\u001b[1;32m---> 14\u001b[0m LHLH_numadult_matrix1,LHLH_numegg_matrix1,LHLH_extinctions_matrix1,LHLH_numadult_matrix2,LHLH_numegg_matrix2,LHLH_extinctions_matrix2 \u001b[38;5;241m=\u001b[39m \u001b[43mMetapop_Simulation_all_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumegg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfood\u001b[49m\u001b[43m,\u001b[49m\u001b[43madnut\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnumegg\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfood\u001b[49m\u001b[43m,\u001b[49m\u001b[43madnut\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgenerations\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreplicates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msen_adden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msen_adsize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m LHLH_metapop_nadult_matrix \u001b[38;5;241m=\u001b[39m Metapop_numadult_matrix(LHLH_numadult_matrix1,LHLH_numadult_matrix2)\n\u001b[0;32m     16\u001b[0m cost \u001b[38;5;241m=\u001b[39m cost_function_2_norm_simplified(migration_45_metapop_nadult_matrix[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3\u001b[39m], LHLH_metapop_nadult_matrix)\n",
      "Cell \u001b[1;32mIn[13], line 81\u001b[0m, in \u001b[0;36mMetapop_Simulation_all_vars\u001b[1;34m(numegg1_start, food1, adnut1, numegg2_start, food2, adnut2, generations, replicates, sen_adden_val, sen_adsize_val, f_val)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,generations):\n\u001b[0;32m     80\u001b[0m     numegg1 \u001b[38;5;241m=\u001b[39m Adult_Module_with_sens_inputs(numadult1,size_female_arr1,adnut1, sen_adden_val, sen_adsize_val)\n\u001b[1;32m---> 81\u001b[0m     numegg2 \u001b[38;5;241m=\u001b[39m \u001b[43mAdult_Module_with_sens_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumadult2\u001b[49m\u001b[43m,\u001b[49m\u001b[43msize_female_arr2\u001b[49m\u001b[43m,\u001b[49m\u001b[43madnut2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msen_adden_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msen_adsize_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     82\u001b[0m     numegg_matrix1[j,i] \u001b[38;5;241m=\u001b[39m numegg1\n\u001b[0;32m     83\u001b[0m     numegg_matrix2[j,i] \u001b[38;5;241m=\u001b[39m numegg2\n",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m, in \u001b[0;36mAdult_Module_with_sens_inputs\u001b[1;34m(numadult, size_female_arr, adnut, sen_adden_val, sen_adsize_val)\u001b[0m\n\u001b[0;32m     17\u001b[0m addens_eff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39msen_adden_val\u001b[38;5;241m*\u001b[39mnumadult)\n\u001b[0;32m     18\u001b[0m fecundity_arr \u001b[38;5;241m=\u001b[39m addens_eff\u001b[38;5;241m*\u001b[39maddens_ind_fec_arr\n\u001b[1;32m---> 19\u001b[0m fecundity_arr \u001b[38;5;241m=\u001b[39m fecundity_arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     20\u001b[0m numegg \u001b[38;5;241m=\u001b[39m fecundity_arr\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m numegg\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#constants - \n",
    "generations = 26\n",
    "replicates = 25\n",
    "f = 0.45\n",
    "numegg = 18\n",
    "\n",
    "#training it on first three metapop replicates\n",
    "\n",
    "def objective_function(x):\n",
    "    objective_function_output_array = []\n",
    "    for k in x:\n",
    "        food = k[0]\n",
    "        sen_adden = k[1]\n",
    "        sen_adsize = k[2]\n",
    "        adnut = k[3]\n",
    "        LHLH_numadult_matrix1,LHLH_numegg_matrix1,LHLH_extinctions_matrix1,LHLH_numadult_matrix2,LHLH_numegg_matrix2,LHLH_extinctions_matrix2 = Metapop_Simulation_all_vars(numegg,food,adnut,numegg,food,adnut,generations,replicates, sen_adden, sen_adsize, f)\n",
    "        LHLH_metapop_nadult_matrix = Metapop_numadult_matrix(LHLH_numadult_matrix1,LHLH_numadult_matrix2)\n",
    "        cost = cost_function_2_norm_simplified(migration_45_metapop_nadult_matrix[:,0:3], LHLH_metapop_nadult_matrix)\n",
    "        objective_function_output_array.append(cost)\n",
    "    return objective_function_output_array\n",
    "\n",
    "options = {'c1': 1.5, 'c2': 1.5, 'w':0.7}\n",
    "min_bound = [0, 0, 0, 0]\n",
    "max_bound = [5, 5, 2, 4]\n",
    "bound_values = (min_bound, max_bound)\n",
    "\n",
    "# Call instance of PSO\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=100, dimensions=4, options = options, bounds= bound_values)\n",
    "# Perform optimization\n",
    "best_cost, best_pos = optimizer.optimize(objective_function, iters=100)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x23730c5d410>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#check if these parameters are able to generate a predictable output\n",
    "optimum_params_acc_pso_all_four_metapop= [3.64684987, 0.12945676, 0.91398383, 2.58379561]\n",
    "food = optimum_params_acc_pso_all_four_metapop[0]\n",
    "sen_adden = optimum_params_acc_pso_all_four_metapop[1]\n",
    "sen_adsize = optimum_params_acc_pso_all_four_metapop[2]\n",
    "adnut = optimum_params_acc_pso_all_four_metapop[3]\n",
    "\n",
    "LHLH_numadult_matrix1,LHLH_numegg_matrix1,LHLH_extinctions_matrix1,LHLH_numadult_matrix2,LHLH_numegg_matrix2,LHLH_extinctions_matrix2 = Metapop_Simulation_all_vars(numegg,food,adnut,numegg,food,adnut,generations,replicates, sen_adden, sen_adsize, 0.45)\n",
    "simulated_pop_optimum_with_trained_on_first_three_reps = Metapop_numadult_matrix(LHLH_numadult_matrix1,LHLH_numadult_matrix2)\n",
    "\n",
    "\n",
    "#checking how it fares wth reproducing training set itself - trained on all four test on all four\n",
    "\n",
    "#boxplot of the population sizes\n",
    "all_points_list = [migration_45_metapop_nadult_matrix[:,0:3].flatten(),simulated_pop_optimum_with_trained_on_first_three_reps.flatten()]\n",
    "plt.boxplot(all_points_list,meanline=True,showmeans=True)\n",
    "plt.ylim(0, 350)\n",
    "plt.xticks([1, 2], ['exp', 'sim'])\n",
    "plt.ylabel('Population size')\n",
    "myHandle = [Line2D([], [], color='orange', lw = 3), Line2D([], [], color='green', linestyle = \"dashed\", lw = 3)]\n",
    "plt.legend(handles = myHandle, labels=['median', 'mean'], frameon = True, loc = 'best', fontsize = 12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-16 16:32:34,541 - pyswarms.single.global_best - INFO - Optimize for 150 iters with {'c1': 1.6, 'c2': 1.6, 'w': 0.7}\n",
      "pyswarms.single.global_best:   0%|          |0/150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pyswarms.single.global_best: 100%|██████████|150/150, best_cost=0.175\n",
      "2023-12-16 17:33:59,387 - pyswarms.single.global_best - INFO - Optimization finished | best cost: 0.17495786400782937, best pos: [2.72030747 0.08998203 0.8557881  1.61678049]\n"
     ]
    }
   ],
   "source": [
    "#train time series using new cost function - with IQRs and stuff both sub and meta\n",
    "#do on all four patches - trianing. Then test 15%  (any othr laternate)\n",
    "\n",
    "#constants - \n",
    "generations = 26\n",
    "replicates = 25\n",
    "f = 0.45\n",
    "numegg = 18\n",
    "\n",
    "#training it on first three metapop replicates\n",
    "\n",
    "def objective_function(x):\n",
    "    objective_function_output_array = []\n",
    "    for k in x:\n",
    "        food = k[0]\n",
    "        sen_adden = k[1]\n",
    "        sen_adsize = k[2]\n",
    "        adnut = k[3]\n",
    "        LHLH_numadult_matrix1,LHLH_numegg_matrix1,LHLH_extinctions_matrix1,LHLH_numadult_matrix2,LHLH_numegg_matrix2,LHLH_extinctions_matrix2 = Metapop_Simulation_all_vars(numegg,food,adnut,numegg,food,adnut,generations,replicates, sen_adden, sen_adsize, f)\n",
    "        LHLH_metapop_nadult_matrix = Metapop_numadult_matrix(LHLH_numadult_matrix1,LHLH_numadult_matrix2)\n",
    "        cost = cost_function_new(migration_45_metapop_nadult_matrix, migration_45_nadult_matrix1, migration_45_nadult_matrix2, LHLH_metapop_nadult_matrix, LHLH_numadult_matrix1, LHLH_numadult_matrix2)\n",
    "        objective_function_output_array.append(cost)\n",
    "    return objective_function_output_array\n",
    "\n",
    "options = {'c1': 1.6, 'c2': 1.6, 'w':0.7}\n",
    "min_bound = [0, 0, 0, 0]\n",
    "max_bound = [5, 5, 2, 4]\n",
    "bound_values = (min_bound, max_bound)\n",
    "\n",
    "# Call instance of PSO\n",
    "optimizer = ps.single.GlobalBestPSO(n_particles=120, dimensions=4, options = options, bounds= bound_values)\n",
    "# Perform optimization\n",
    "best_cost, best_pos = optimizer.optimize(objective_function, iters=150)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.25 trail 1 - [3.08092332 0.10182029 0.8933751  1.8015495 ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
